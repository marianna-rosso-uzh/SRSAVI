[
  {
    "objectID": "abstracts.html",
    "href": "abstracts.html",
    "title": "SR-SAVI Conference",
    "section": "",
    "text": "Talks\n\n\n\n\n\n\nAlexandra Bannach-Brown - Barriers and enablers to conducting systematic reviews at a German University Medical Center – Findings from the “Communities for Open Research Synthesis” project\n\n\n\n\n\nBerlin Institute of Health @ Charite, Berlin, Germany\nBannach-Brown, Alexandra: Kohrs, Friederike Elisabeth; Amin Tariq, Ayesha; Vojvodic, Sofija; Karmakar, Mala; Rackoll, Torsten; McCann, Sarah\nCommunities for Open Research Synthesis (COReS) develops a targeted framework to initiate systemic change in how evidence from preclinical studies is translated into improved human health outcomes. Systematic review and meta-analysis are research synthesis tools that advance high-quality research by evaluating how reliable evidence is and clearly identifying knowledge gaps, highlighting where future research is needed. We employ a three-pillar approach to integrate preclinical systematic reviews into the research pipeline and foster synthesisable primary research practices; building capacity with open-access training opportunities and comprehensive online resources for researchers and stakeholders at all experience levels (education); scaling capacity for synthesisable research and systematic review conduct by developing tools and software (infrastructure); and forging networks through interdisciplinary learning and collaboration opportunities (community). With this sub-study, we aimed to identify barriers and enablers to conducting systematic reviews and identify current practices to systematic review conduct at one of the largest European university medical centres (UMCs), Charité. We surveyed all UMC staff members (including researchers, research support staff, clinicians, and other) about their awareness of and attitudes towards systematic review. We conducted follow-up interviews with interested survey participants to examine attitudes and current practices towards systematic reviews. We further present our strategy to extend this survey to all UMCs across Germany to inform our nationwide implementation strategy. Our findings highlight specific barriers and enablers identified by multiple stakeholders when conducting systematic reviews at a European University Medical Center. We use these findings within the COReS project to develop sustainable implantation strategies to enact long-lasting change in how preclinical research is designed, conducted, and disseminated considering up-to-date evidence.\n\n\n\n\n\n\n\n\n\nCarolyne Huang - A simulation study to quantify successful translation of results from preclinical studies to human trials\n\n\n\n\n\nUniversity of Zurich\nHuang, Carolyne; Heyard, Rachel\nDrugs that show promising results in animal preclinical studies frequently fail to do the same in human clinical trials, a phenomenon known as the “translational failure”. Currently, there is no agreed-upon metric to quantify translational success between these two inherently different populations. However, there is a growing body of literature on quantifying the success of a replication of an original finding. While translation and replication are not exactly the same, the metrics developed for replication success could be useful in the translation setting.This simulation study aims to explore the behavior and characteristics of such replication success metrics under various simulation conditions designed to mimic real-world translation settings, and ultimately assess the usefulness of these metrics in defining translation success.The data-generating mechanism is based on a previously published meta-analysis assessing the effect of prenatal amino acid supplementation on maternal blood pressure. The data includes both animal and human studies investigating the same treatment and outcome, which ensures the plausibility of our data-generation process. Animal and human studies are simulated under different conditions: (1) null and alternative animal and human hypotheses, and (2) powered vs. non-powered animal studies. Additionally, the study investigates various criteria to continue from an animal experiment to a human study, e.g., a human study is performed only if a meta-analysis of three independent animal studies demonstrates a significant beneficial effect. The previously developed replication success metrics are applied to the results of the simulated animal and human studies. From this, we can calculate the share of successful translations under each of the simulation conditions in order to determine which metric performs well in which conditions. We adhered to best practices when designing our simulation study, including pre-registering a study protocol on the Open Science Framework before running the simulation. –\n\n\n\n\n\n\n\n\n\nJoelle Jagersma - Animal models for the social, cognitive, and neurobiological impact of early-onset hearing loss: a systematic review with synthesis without meta-analysis (SWiM)\n\n\n\n\n\n1 Department of Otorhinolaryngology and Head/Neck Surgery, University of Groningen, University Medical Center Groningen, Groningen, The Netherlands. 2 Neurobiology, Groningen Institute for Evolutionary Life Sciences, University of Groningen, Groningen, The Netherlands. 3 Dept. of Anaesthesiology, Pain and Palliative Medicine, Radboud University Medical Center, Nijmegen, The Netherlands.\nPrado Rivera, Mayerli 2; Deddens, Verena 2; Wever, Kimberley E. 3; Olivier, Jocelien D. A. 2; Pyott, Sonja J 1\nExtensive research indicates that hearing loss in children can lead to impairments in social and cognitive (learning and memory) development. To reduce these deficits in children, novel treatment options are needed. However, it is still unknown how exactly hearing loss results in diminished social and cognitive development. Several animal models have been developed to address this problem, which vary widely in terms of hearing loss onset and severity, the induction method, and outcomes (e.g. assessments of social and cognitive behavior and involved neurobiological structures). Given this high level of variability between studies and their findings, a systematic review is essential and timely. This systematic review aims to synthesize findings from animal studies on early onset hearing loss, with a focus on both investigating its impact on social and cognitive behaviors and identifying the associated underlying neurobiological mechanisms.The review methodology was prospectively registered in PROSPERO (ID: CRD42024515848) and adhered to SYRCLE’s systematic review protocol for animal intervention studies (de Vries et al., 2015). A comprehensive search was performed in PubMed and Embase to identify animal models with early onset hearing loss. The complete search strategy encompassed the search components “animals” (Hooijmans et al., 2010), “hearing loss”, and “social or cognitive behaviors”. Screening of papers occurred largely manually but was supported by artificial intelligence. Outcome parameters were categorized as cognitive, social or vocal behavior, or as neurobiological outcomes. Synthesis of the data occurred though synthesis without meta-analysis (SWiM). (Results & Conclusion) A wide variety of animal models has been captured in the current review. Synthesis of outcome parameters is ongoing, but aims to highlight gaps in current research. The outcomes of this research will guide future animal studies towards targeted investigations of potential treatments against the negative effects of hearing loss on the social and cognitive domains.(see section above)\n\n\n\n\n\n\n\n\n\nOtto Kalliokoski - It is time to talk about fraudulent studies in meta-analytical evidence synthesis – learnings from a preclinical systematic review\n\n\n\n\n\nDepartment of Experimental Medicine, University of Copenhagen\nBerrío, Jenny; Kalliokoski, Otto\nOur current best practices for the conduct of systematic reviews leaves our evidence synthesis vulnerable to the influence of fraudulent papers. Whereas we have, for example, methods for assessing the influence of publication bias and checklists for quality of reporting, we have virtually no methods for assessing the actual veracity of the information in a study. This is a problem since we are learning that the number of fraudulent studies in biomedical science is far higher than previously suspected. What happens to the evidence gathered in a systematic review when fraudulent studies are included? In a preclinical systematic review concerning a popular model for studying depression in rats, we encountered numerous studies featuring problematic images. Some of these image issues were very difficult to explain as something other than the result of outright falsification or fabrication. Our objective thus became to estimate how common potentially fraudulent papers are by using papers with this type of image issues as a proxy, and to find out how they influence the findings of a preclinical systematic review. While carrying out full text screenings we chose to record the number of studies with problematic images and to characterize the types of issues we encountered. Moreover, we obtained journal and paper level meta-data. We then carried out a sensitivity analysis using the ten studies with problematic images that were included, post-screenings, in our review. We gauged their influence on the synthesized effect size and compared how they fared with respect to risk of bias and quality of reporting metrics.We screened 1,035 papers, where approximately half (57%) contained images we could analyze. Of the papers that we were able to assess, 19% (112 studies) contained problematic images. It is furthermore our assessment that a majority of these could not easily be explained as honest mistakes, and in quite a few cases, we could point to outright falsification or fabrication in the images. Basic bibliometrics like journal impact factor or number of citations to a paper could not be used to distinguish problematic papers. Standardized check lists for quality of reporting and risks of bias were similarly unhelpful in identifying potentially fraudulent papers. Alarmingly, the papers with problematic images seemed to produce higher effect estimates, skewing our systematic review results significantly. The lack of a consensus on how to deal with problematic papers in systematic reviews is a problem. Currently, Cochrane recommends removing papers from reviews only if they have been retracted or if it can be clearly shown that the data is somehow untrue. Following these types of recommendations are not sufficient to combat the influx of fraudulent data. If we do not develop better safeguards for excluding potentially fraudulent studies in our evidence synthesis methods, systematic reviews will quickly lose their value. It is time we have an open conversation on how we want to address the problems these types of studies pose.\n\n\n\n\n\n\n\n\n\nMala Karmakar - Open Data Commons for Stroke: a free community platform to share research data and facilitate synthesis\n\n\n\n\n\nNA\nSarah McCann, Alexandra Bannach-Brown, Sofija Vojvodic, Torsten Rackoll, Mala Karmakar\nDespite efforts to promote open data sharing, uptake remains limited in biomedical research, and shared data is often difficult to locate and reuse. This is particularly challenging for evidence synthesis, where locating relevant data can be time-consuming and ineffective. Furthermore, many null or negative results remain unpublished, leading to skewed interpretations and research waste.The Open Data Commons (ODC) aims to address these challenges by providing a cloud-based, community-driven platform for sharing, managing and publishing primary research data. It supports FAIR data principles (Findable, Accessible, Interoperable, Reusable) and facilitates evidence synthesis in translational biomedicine. This work aims to develop ODC-Stroke, a platform tailored to preclinical ischaemic stroke research.ODC-Stroke offers secure login with varied permissions for data uploading, sharing, and publishing. Preclinical stroke researchers can control data visibility, and all published datasets receive DOIs for citation and reuse. The platform is optimized for single and multi-laboratory studies. Further, ODC-Stroke allows evidence synthesis to incorporate unpublished data, which expands the scope and reliability of systematic reviews, addressing publication bias and supporting more comprehensive and sophisticated analyses. ODC-Stroke is developed through collaboration with preclinical stroke researchers to co-create a network to develop common data elements (CDEs) and integrate primary data collection with evidence synthesis pipelines. This ensures data interoperability, reusability, and more effective evidence synthesis across studies.ODC-Stroke provides a robust resource for sharing curated data, promoting collaboration, and supporting reproducibility. By offering access to individual subject data and promoting common data elements, ODC-Stroke can enhance the efficiency of systematic reviews and reduce publication bias, thereby improving data management and research integrity.\n\n\n\n\n\n\n\n\n\nAileen MacLellan - Assessing scientific rigour and 3Rs implementation in Canadian research: An investigation of animal use protocols\n\n\n\n\n\nOttawa Hospital Research Institute, University of Ottawa\nAvey, Marc; Fergusson, Dean; Lalu, Manoj\nEthical review of animal experiments is a potentially powerful mechanism for enhancing rigour and implementation of the 3Rs (replacement, reduction, refinement). However, previous assessments have revealed high risk of bias in animal use protocols, and an incomplete understanding of the 3Rs within ethical review committees. In Canada, reporting within animal use protocols has never been investigated. We therefore sought to assess current information provided to ethical review committees to identify areas for improvement. In partnership with Canada’s oversight body for animal science, the Canadian Council on Animal Care (CCAC), we are conducting a cross-sectional study of approved animal use protocols to characterise reporting of 1) rigorous methodology (randomization, blinding, sample size calculation, planned data analysis); and 2) the 3Rs. In coordination with the CCAC, a request for submission of animal use protocols was sent to 35 academic institutions. The last three mouse and three rat protocols approved prior to January 1, 2024 for minimal, low, moderate and severe stress categories of invasiveness, in both basic and translational research were requested from each academic institution (n=48 protocols/institution). Screening and data extraction were performed in duplicate by two independent reviewers.Fifteen institutions participated (43%), submitting 300 protocols (mice n=184, rats n=116). Data extraction and analyses are ongoing. Preliminary assessments of 142 protocols show reporting of blinding in 4% of protocols, randomization in 14%, sample size calculation in 37%, and planned data analysis in 20%. Efforts to replace and reduce animal use in experiments were reported in 39% and 59% of protocols, respectively; and refinements were reported in 20%. Although incomplete reporting of rigour and the 3Rs was common, understanding variation in these areas is critical for improvement. Our study will lay essential groundwork for ‘evidence-informing’ updates to CCAC policy, and support for researchers and ethical review committees.\n\n\n\n\n\n\n\n\n\nMartijn Nolte - Better Science through More Transparency: Pilot study on stimulating transparent laboratory animal research\n\n\n\n\n\nZonMw\nMenon, Julia; De Waard, Bas; Ritskes-Hoitinga, Merel\nIn 2019 , the Dutch House of Representatives passed a motion asking the government to investigate ways to increase the transparency and quality of animal research. Based on this motion, the Ministry of Education, Culture, and Science assigned ZonMw, the largest funder of biomedical research in The Netherlands, to investigate the impact on the research practice of several transparency methods, including systematic reviews. This pilot study aimed to address how researchers and other stakeholders perceive various transparency methods, what hurdles exist in applying these methods, and the feasibility of their effective implementation. Concerning systematic reviews, the main question was whether systematic reviews should be made a prerequisite, for instance for obtaining ethical approval to perform animal experiments.Researchers and stakeholders involved in biomedical research were asked through online questionnaires and semi-structured interviews about their experiences and perspectives regarding these transparency methods: Preregistration, Data management plans and FAIR data, ARRIVE guidelines, Open access publishing and Systematic reviews. Interviewees acknowledged the value of systematic reviews but deemed them impractical due to their time-consuming nature, high demand in terms of skills and cost, and bureaucratic hurdles. Alternative approaches consider demanding them in specific situations that would benefit the field or using a systematized approach to better justify chosen animal models in ethical applications. Existing funding initiatives supporting systematic reviews are deemed valuable and encouraged to be sustained.Systematic reviews are considered valuable and could be promoted in certain contexts, but having them as a requirement is not yet feasible. A separate study would be of value to assess when and how such reviews should be applied, how they should be promoted, or made compulsory. Moreover, teaching the methodology of systematic reviews in academic bachelor or master courses is considered highly valuable to prepare the next generation of scientists to perform such reviews.\n\n\n\n\n\n\n\n\n\nYiyuan Pu - Large Language Models in systematic review automation of Alzheimer’s research: enhancing living evidence landscape with PICO entity extraction\n\n\n\n\n\nSchool of Computing and Information Systems, The University of Melbourne; Centre for Clinical Brain Sciences, The University of Edinburgh; School of Computing Technologies, RMIT University; School of Computing and Information Systems, The University of Melbourne; Centre for Clinical Brain Sciences, The University of Edinburgh; School of Computing Technologies, RMIT University\nYiyuan, Pu; Kaitlyn, Hair; Daniel, Beck; Mike, Conway; Malcolm, MacLeod; Karin, Verspoor\nAD-SOLES (Systematic Online Living Evidence Summary of Alzheimer’s Disease Research) conducts living systematic reviews for preclinical Alzheimer’s research. Summaries of existing AD research are abstracted as PICO elements (Population, Intervention, Comparator, and Outcome), providing the latest combinations of models, treatments, and outcome measures. A standard method in automating PICO extraction is to apply a dictionary compiled from a set of regular expression (regex) patterns in literature. We explored improving the regex performance of intervention extraction with Large Language Model-based (LLM-based) filtering in AD-SOLES. We aim to extend the LLM-based filtering method from intervention extraction alone to all PICO elements in preclinical AD studies. For automatically identifying PICO elements, we ​​followed a two-stage filtering method in the intervention extraction of AD studies. We used a Pre-trained Language Model (PLM) to filter false positives obtained from regexes. Precision errors arising from regex-based methods were mainly due to a lack of context: any entity that matched a regex would be recognized as an intervention. We hypothesized that a PLM can contextualize entity context and filter them out if appropriate, without undermining recall. Preliminary results on intervention extraction show the two-stage filtering outperforms strong baselines, including standalone use of LLMs. For intervention extraction, a Regex-based method achieved an F1 score of 32%, and ChatGPT and GPT-4 with zero-shot learning achieved F1 scores of 29% and 27% respectively. In the Regex+ChatGPT (three-shot) scenario, the model achieved the highest F1 of 50%. Experiments of other PICO elements are in progress.PICO entity extraction with LLM-based two-stage filtering leads to more reflective summaries of Alzheimer’s studies, supporting literature-based discovery in the future. This further helps experts prioritize treatments for clinical experiments and discover drug combinations for symptoms.\n\n\n\n\n\n\n\n\n\nAndrew Rooney - Improving workflow for evidence-based decision making in environmental health evaluations\n\n\n\n\n\nDivision of Translational Toxicology (DTT), National Institute of Environmental Health Sciences (NIEHS), National Institutes of Health (NIH), Research Triangle Park, NC, USA\nWalker, Vickie\nSystematic review methods provide objectivity and transparency to the process of identifying, critically assessing, and synthesizing scientific evidence to answer environmental questions and guide public health decisions. Although, there have been significant advances in artificial intelligence (AI) and information processing, human health assessments of environmental exposures are largely developed with manual procedures. The construction of a streamlined workflow for literature-based assessments that leverages automation and AI is crucial for reducing the time and resource demands of the traditional systematic review approach. By leveraging AI and automation, the Division of Translational Toxicology’s (DTT) at the National Institute of Environmental Health Sciences enhanced assessment workflow aims to improve efficiency and accuracy while maintaining the rigorous standards of systematic review methodologies. This presentation outlines an enhanced workflow incorporating AI tools and human-in-the-loop procedures for systematic reviews and systematic evidence maps to support the accuracy necessary for public health decisions and the capacity to handle large datasets and facilitate the collection of complex information across environmental health science literature. The literature screen and extraction steps are some of the most time-consuming steps (~30% of total review time) and impactful targets for automation, particularly for environmental health questions, given the breadth of study designs and endpoints represented. By automating repetitive tasks, researchers can focus on more critical aspects of the review, such as interpreting results and synthesizing the evidence to reach conclusions. DTT’s workflow also supports transparency and reproducibility by providing clear documentation, interactive figures, and standardized procedures for each stage of the process. In this work, we present a framework that demonstrates the potential of AI and automation to significantly reduce level of effort for systematic reviews and remove barriers to their use and accessibility ensuring that decision-making is both timely and evidence based.\n\n\n\n\n\n\n\n\n\nClara Sanchez-Izquierdo Lozano - Methodological assessment of in vitro systematic reviews: a systematic review\n\n\n\n\n\nCentre for Clinical Brain Sciences, University of Edinburgh, Edinburgh EH8 9YL, UK; Berlin Institute of Health at Charité, Universitätsmedizin Berlin, Charitéplatz 1, 10117, Berlin, Germany; Sheffield Institute for Translational Neuroscience, University of Sheffield, Sheffield, S10 2HQ, UK; Clinical Epidemiology Program, Blueprint Translational Research Group, Ottawa Hospital Research Institute, Ottawa, Ontario, Canada\nSanchez-Izquierdo Lozano, Clara; Hair, Kaitlyn; Smith, Sean; Arroyo Araujo, Maria; McColl, Barry; McCann, Sarah; Livesey, Matthew; Lalu, Manoj; Sena, Emily; Malcolm, Macleod\nIn vitro research is an integral component of understanding disease, furthering drug development and addressing the 3Rs (replacement, reduction and refinement) of in vivo animal models. Systematic reviews provide a comprehensive summary of evidence and preclinical systematic reviews are crucial in translation of preclinical results to clinical settings. Systematic review protocol templates exist for clinical and preclinical in vivo systematic reviews. In vitro research has unique aspects, such as various cell line or tissue culture models, that are not shared with clinical research or preclinical in vivo research, therefore systematic review approaches used in those contexts are not appropriate or effective and must be adapted to the unique domain of in vitro studies. Currently, no such template exists for in vitro systematic reviews which can have huge consequences on the quality of in vitro systematic reviews and subsequently, a negative impact on the preclinical to clinical translation.We aim to perform a systematic review of all published in vitro systematic reviews to identify key variables in their guidance, methodologies and conduct to inform the development of an infrastructure for performing in vitro systematic reviews. Having a developed protocol will provide a robust outline of how best to conduct such reviews and thus improve their reproducibility and rigour.We will search PubMed, SCOPUS and Web of Science (ISI). Our search strategy will include two main components: (1) terms related to in vitro and (2) terms related to systematic reviews or meta-analyses. ASySD will be used to deduplicate results and SyRF will be used subsequently for screening and data extraction. Study characteristics extracted will be related to reporting quality and tools employed to conduct the in vitro systematic reviews. From this, we will curate a “long-list” of potential in vitro systematic review methodologies and perform a Delphi approach with corresponding authors from the identified in vitro systematic reviews and our international advisory board of experts in the field. Each step of the systematic review process will be assessed for the most appropriate methodological option to create an agreed infrastructure for conducting in vitro systematic reviews.Still ongoingStill ongoing\n\n\n\n\n\n\n\n\n\nSara Steele - Underreporting in non-clinical publications: Development of the rigor assessment tool (RAT)\n\n\n\n\n\nKU Leuven and Johnson & Johnson\nLavrijssen Tom; Steckler, Thomas\nThe failure rate in drug development is as high as 90% for drug candidates reaching phase I clinical trials and even higher when drug candidates from the preclinical phase are considered. The problem is multifold with one of them being issues with internal and external validity of non-clinical studies, which is in part, reflected by studies reporting on the difficulty to reproduce published research findings. A strategy to increase internal validity is lowering the risk of bias by adherence to rigorous experimental design, both for internally and externally generated data. We developed the “Rigor Assessment Tool”, an advanced data driven methodology to predict research rigor-related risks associated with a potential external business partner, based on an analysis of past scientific publications from that research unit. We explored the standards of reporting in non-clinical publications, developed an information extraction tool based on expert opinions and validated the information provided in articles. Further analyses are ongoing, but eventually we should have a full working tool that can, among other things, guide decisions when planning to engage with external partners, be used to further support the prioritization of audit planning in preclinical QA and address the issue of poor reproducibility of published data. Eventually, this tool might help to decrease the failure rate in drug development.\n\n\n\n\n\n\n\n\n\nFrancesca Tinsdeall - A Comprehensive Evaluation of Stopping Rules in Technology-Assisted Review: When Have We Screened Enough?\n\n\n\n\n\nCentre for Clinical Brain Sciences, University of Edinburgh\nTinsdeall, Francesca; Macleod, Malcolm; Callaghan, Max; Stevenson, Mark; O’Mara Eves, Alison; Thomas, James\nSystematic reviews aim to identify research articles relevant to a review question. Screening articles for inclusion is time-consuming, especially when search strings yield large volumes. Technology-assisted review (TAR) employs a classification model trained via active learning to rank articles by relevance, which determines their order of presentation for human screening. This ‘prioritised screening’ may reduce time spent reviewing irrelevant articles and is commonly used in clinical reviews and legal eDiscovery. However, the absence of well-validated tools for determining when to stop reviewing the ranked list whilst maintaining desired recall often forces researchers to review all articles, obviating the efficiency gains of TAR. TAR stopping rules are designed to determine when desired recall has been met and human screening can stop. To date, there has been no thorough evaluation of these rules across different systematic review contexts. This study will comprehensively assess the accuracy and reliability of available stopping rules across various contexts and ranking algorithms.This study will review and then evaluate stopping rules applicable to the systematic review process. Evaluation metrics will prioritise high recall and will focus on reliability and confidence in estimated stopping points. The simulation datasets used will include clinical and preclinical systematic reviews. Subgroup analyses will consider the classification model, effectiveness of prioritisation, review context, and dataset characteristics. This research will provide empirical evidence on the efficacy and reliability of TAR stopping rules and highlight context-specific factors which should guide the choice of stopping rule used for a particular screening task. Clearer guidance on selecting and using stopping rules within the TAR framework will enable researchers to utilise TAR more effectively, reducing human time and effort without compromising review quality. The results of this work will enhance decision-making in the design of both living and non-living systematic review methodologies.\n\n\n\n\n\n\n\n\n\nUlf Tölch - The future of Systematic Online Living Evidence Summaries (SOLES): emerging trends and challenges in automating evidence synthesis\n\n\n\n\n\nCharité | BIH QUEST Center for Responsible Research\nLarge language models carry the promise to support evidence synthesis with their probabilistic representations of human research artefacts, particularly written text. Here, we explore the capability of cloud based commercial large language models to evaluate published experimental papers from a broad range of fields. We compare LLM performance (same responses as human reviewers) across different architectures and pipelines on established quality criteria for scientific publications. We show that easy tasks can be achieved with almost the same accuracy of human reviewers. With increasing assessment difficulty accuracy levels drop and additional reconciliation is needed. We present guidance how this can be achieved and make suggestion for next steps.\n\n\n\n\n\n\n\n\n\nKimberley Wever - Uncovering Duplicated Images in Scientific Literature - Systematic Review as a Tool for Detection\n\n\n\n\n\nRadboud University Medical Center\nAquarius, Rene; van de Voort, Merel; Reesink, Manon; Wever, Kimberley E.\nWhile performing a systematic review of preclinical evidence for interventions against early brain injury after subarachnoid hemorrhage, we came across multiple cases of image manipulation and duplication in the included publications.To quantify and characterize image duplication and manipulation in the publications included in this systematic review.After screening for eligibility, 612 publications were included in the systematic review. For each publication, we used ImageTwin (AI driven software) to detect image duplication within each publications, as well as between each publication and the ImageTwin database of ~50 million scientific images. We also assessed image duplication and manipulation by eye. Furthermore, we reviewed whether the publication had previously been 1) reported on PubPeer; 2) retracted or 3)corrected using an erratum / corrigendum.We found duplicated images in 179 out of the included 612 publications (29.2%). We found that 95 publications contained overlapping or duplicated images within a single figure, 34 showed overlaps or duplications between figures within the publication, and 65 publications contained figures which overlapped with, or were duplicates from different publications. When assessing the journals in which these problematic studies were published, we found that all major (biomedical) publishers were represented.Image manipulation and duplication can pose a significant threat to our confidence in an evidence base, but their prevalence is largely unknown. Systematic reviews provide a unique opportunity to identify duplicated images, especially between studies in a specific field of research. Our current assessment proves that the quality of the body of evidence is compromised in this field, which has negative consequences for data synthesis.\n\n\n\n\n\n\n\n\n\nCharis Wong - Selecting amantadine as the 3rd experimental arm for MND-SMART using a data-driven framework\n\n\n\n\n\nCentre for Clinical Brain Sciences, University of Edinburgh.\nWong, Charis; Cardinali, Alessandra; Liao, Jing; Selvaraj, Bhuvaneish T.; Baxter, Paul; Carter, Roderick N.; Longden, James; Graham, Rebecca E.; Dakin, Rachel S.; Pal, Suvankar; Chataway, Jeremy; Swingler, Robert; Hardingham, Giles E.; Carragher, Neil; Chandran, Siddharthan; Macleod, Malcolm R.\nDespite decades of clinical trials, effective disease modifying treatment options for motor neuron disease (MND) remain limited. There is a pressing need to identify effective disease modifying treatments. Motor Neuron Disease-Systematic Multi-Arm Adaptive Randomised Trial (MND-SMART; ClinicalTrials.gov number: NCT04302870) is a multi-arm multi-stage, adaptive platform trial testing a pipeline of candidate drugs.Building upon systematic reviews to inform initial drug selection, we aimed to develop and implement the Systematic Living Evidence for Clinical Trials (SyLECT) framework, a modular, systematic, framework using diverse data to inform ongoing selection by expert panel.We gathered, synthesised, integrated and reported evidence from different domains to identify, evaluate, and prioritise candidate drugs. Domains included: published literature through Repurposing Living Systematic Review-Motor Neuron Disease (ReLiSyR-MND), a machine learning assisted systematic review of clinical literature of MND and othe neurodegenerative diseases which may share similar pathways, animal in vivo and in vitro literature of MND and frontotemporal dementia; in vitro high throughput drug screening; pathway and network analysis; and drug, chemical and clinical trial registry databases.We identified candidate drugs (ReLiSyR: 303, drug screening: 287, network analysis: 1144). We longlisted 49 drugs and synthesised further evidence across domains. We shortlisted 9 drugs and selected amantadine for evaluation in MND-SMART. Amantadine showed good efficacy and safety across 59 clinical publications, reduced TDP-43 aggregates on in vitro screening and was predicted to be active on multiple targets associated with MND. Amantadine was added as the third experimental arm of MND-SMART in April 2023.We demonstrated the feasibility and synergistic benefits of a systematic, multimodal, data-driven framework to inform drug selection for MND clinical trials, with potential for application across other disease areas.\n\n\n\n\n\nPosters\n\n\n\n\n\n\nJuliana Bolzan - An overview of protocols in Pharmacology registered at PROSPERO: Are there systematic reviews and meta-analyses synthesizing pharmacological interventions?\n\n\n\n\n\nDepartment of Physiological Sciences, Center of Biological Sciences, Federal University of Santa Catarina (UFSC)\nBolzan, Juliana Aparecida; Lino de Oliveira, Cilene.\nPharmacological evidence is crucial for translational research, drug discovery, and development. Pharmacologists can synthesize the available information, increasing the validity of conclusions in individual studies and identifying gaps using systematic reviews (SR) and meta-analyses (MA). However, SRMA is time-consuming, requiring reviewers’ knowledge and skills, which may discourage pharmacologists from conducting them. Here, the aim is to investigate whether and how SRMAs are being conducted in Pharmacology. For this, an umbrella overview was planned, preregistered (https://osf.io/df3kg), and carried out as follows: 1- searches for SR protocols at the PROSPERO repository; 2- screening to include protocols with any population, pharmacological intervention, comparison, and outcome; 3- extraction of data on authors identification, protocol stage, analytical and updating plans.From 1.744 protocols retrieved, 232 were included after screening (146 planned to make an MA, 38 SRMA were complete or published, and none planned for updating). “All animals” were the most frequent population (n=88) followed by rodents (n=42), rats and/or mice (n=24), or rats only (n=14). “Non-human animals”, “only mammals”, in vivo, in vitro and/or ex vivo models were less frequent (n&lt;10). The interventions were antibiotics (n=23), cannabinoids (n=20), antidiabetics (n=19), antineoplastic drugs (n=16), antidepressants (n=15), and others (n≤10: analgesics, anti-inflammatories, anesthetics, antihypertensives, statins, anthelmintics, psychostimulants, immunosuppressants, neuroprotective or anxiolytic agents). The more frequent outcomes were scores for neuropsychiatric disorders (n=40), followed by cardiovascular disorders (n=28), infections (n=20), neoplasms (n=18), pain disorders (n=15), endocrine disorders (n=13), inflammatory and neurodegenerative disorders (n=11). Outcomes of other modeled conditions were less common (n&lt;10, bone disorders, injuries, lung disorders, wound healing, cartilage damage, renal disorders, toxicity, orthodontic treatment, and atopic dermatitis).Despite the possible challenges and difficulties, pharmacologists of all fields are interested in conducting SRMAs. In the next few years many SRMA in Pharmacology are expected to be published. Nevertheless, obsolescence seems risky because no plans for updating were found.\n\n\n\n\n\n\n\n\n\nJessica Cait - The impact of social isolation on laboratory rodent health and data replicability: a systematic review and meta-analysis\n\n\n\n\n\nUniversity of Guelph & The Canadian Council on Animal Care\nCait, Jessica; Avey, Marc T.; Mason, GJ\nOver 120 million mice and rats are used in research globally each year, many of which are isolated in barren shoebox-sized cages that are poor for welfare. In humans, chronic stress increases disease susceptibility and reduces lifespans. Our previous meta-analysis showed that, compared to those in larger cages equipped with resources that allow the expression of natural behaviour, rodents in conventional cages (small and relatively barren) are more susceptible to stress-sensitive diseases (anxiety, cancer, cardiovascular disease, depression, stroke) and have shortened lifespans. Further, meta-analyses of statistical interactions between housing conditions and disease modifiers (e.g., therapeutic drugs) revealed that these effects can alter experimental results, impacting data replicability. We aim to build on our previous work on barren cages, investigating similar chronic stress effects in individually housed rodents. We hypothesize that poor welfare from social isolation harms animal health and changes research results, impacting data replicability.We searched five databases (Ovid, CABI, Web of Science, Proquest, SCOPUS) on May 26, 2024. 2,384 titles and abstracts were screened in duplicate for eligibility (published in English, using mice or rats, and using social isolation as an intervention), and full-text screening of 375 articles is underway. Random effects meta-analyses (including meta-analyses of statistical interactions) will be conducted to test hypotheses. Risk of bias will be assessed using SYRCLE’s RoB tool.Available in October.Results will help us understand how social isolation impacts laboratory rodents’ wellbeing and address whether isolation can alter experimental conclusions, thus reducing the replicability of animal-based research. These data, combined with previous work on rodent housing, will allow us to assess the relevance of welfare as a biological variable that should be considered when conducting in vivo studies.\n\n\n\n\n\n\n\n\n\nMaria Economou - Identifying and addressing challenges in automating evidence synthesis of increasingly large datasets\n\n\n\n\n\n1 CAMARADES Berlin, QUEST Center for Responsible Research, Berlin Institute of Health at Charité (BIH), Berlin, Germany; 2 Institute for Laboratory Animal Science, Faculty of Medicine, RWTH Aachen University, Aachen, Germany ; 3 Centre for Clinical Brain Sciences, University of Edinburgh, Edinburgh, UK\nEconomou, Maria1; Mirzaei, Yalda2; Ahmadvand, Ardalan2; Hair, Kaitlyn 3; Smith, Sean3; Steitz, Julia2 ; McCann, Sarah1; Bannach-Brown, Alexandra1\nAs synthesizing rapidly increasing bodies of evidence becomes a priority, methodological advances are needed to expedite systematic review of published literature. Systematic Online Living Evidence Summaries (SOLES) are one such novel approach to streamline the key stages of evidence synthesis, incorporating automated processes to search for, categorize, summarize and visualize research findings. Addressing the challenges of automating synthesis of large datasets is an important issue, especially considering the skyrocketing number of scientific publications in biomedicine. We aim to describe the surfacing challenges associated with applying automation tools on large bibliographic datasets and identify strategies for improvement.This work is done in the context of developing Cancer-SOLES, a workflow designed to facilitate the up-to-date evaluation and synthesis of studies testing small molecule therapies in animal models of cancer. Challenges at each stage of the workflow are considered, including hitting rate limits in weekly literature searches via application programming interfaces, large-scale deduplication, machine-assisted screening of records in batches, substantive metadata retrieval, bulk annotation of study characteristics, and the presentation and loading times of summary tables and visualizations in an online dashboard. Initial searches for Cancer-SOLES across four databases yielded over 1.3 million potentially relevant articles. This significantly impacted automated approaches. For instance, current programming tools for deduplication and citation screening are limited in processing smaller subsets of data at once. These constraints could lead to downstream challenges such as the ineffective removal of duplicate records in very large datasets or reducing screening accuracy. Understanding the obstacles that large datasets pose on automating key steps of evidence synthesis will allow us to identify approaches to effectively improve our current tool workflow, both in terms of accuracy and performance, as well as computational efficiency. These insights are timely and relevant as automation becomes an integral part of synthesizing rapidly emerging research output.\n\n\n\n\n\n\n\n\n\nMatheus Gallas-Lopes - Ten years of unpredictable chronic stress research in zebrafish: a systematic review and meta-analysis\n\n\n\n\n\nPharmacology Department, Universidade Federal do Rio Grande do Sul\nGallas-Lopes, Matheus; Bastos, Leonardo M.; Benvenutti, Radharani; Panzenhagen, Alana C.; Piato, Angelo; Herrmann, Ana P.\nZebrafish (Danio rerio) are increasingly used to study the neurobehavioral effects of stress. The first study on unpredictable chronic stress (UCS) in zebrafish was published just over a decade ago, adapted from rodent protocols. However, subsequent studies have yielded inconsistent results.This study aimed to evaluate the effects of UCS on zebrafish behavior and relevant biomarkers through a systematic review and meta-analysis.We conducted a comprehensive literature search across three databases (PubMed, Scopus, and Web of Science) using a two-step screening process with defined inclusion and exclusion criteria. Data extracted from qualified studies (n=38) included qualitative and quantitative information, along with a risk-of-bias assessment. For meta-analyses, the outcomes were grouped into the following categories: anxiety/fear behavior, locomotor function, social behavior, and cortisol levels.UCS exposure increased anxiety/fear behaviors (SMD 1.09, 95%CI [0.50;1.6]) and cortisol levels (0.66, [0.06;1.25]) while decreasing locomotion (−0.56, [−1.02;−0.10]). Social behavior, however, did not show a statistically significant overall effect (−0.30, [−0.77;0.17]). Despite a substantial number of studies included, high heterogeneity and methodological/reporting issues identified during the risk-of-bias assessment raised concerns about the internal validity of individual studies and the overall generalizability of this model. Interestingly, subgroup analysis revealed that stress regimens exceeding a week significantly impact anxiety, movement, and cortisol levels, while protocols lasting up to 7 days do not. This suggests a milder stress response for shorter durations and highlights the importance of protocol duration in zebrafish chronic stress studies.This review emphasizes the need for well-designed experiments and standardized stress protocols to understand the impact of UCS on various behavioral aspects of zebrafish. Future studies should employ robust methodologies and transparent reporting to strengthen the zebrafish model for chronic stress research.\n\n\n\n\n\n\n\n\n\nBenjamin Ineichen - Key experimental parameters from animal studies are not associated with successful animal-to-human translation in multiple sclerosis drug development – systematic review and meta-analysis\n\n\n\n\n\nUniversity of Zurich\nBerg, Ingrid; Härvelid, Pia; Zürrer, Wolfgang Emanuel; Rosso, Marianna; Reich, Daniel Salo; Ineichen, Benjamin Victor\nDespite successes in multiple sclerosis (MS) drug development, the effectiveness of animal studies in predicting successful bench-to-bedside translation is uncertain. Our goal was to identify predictors of successful animal-to-human translation for MS by systematically comparing animal studies of ap-proved disease-modifying therapies (DMTs) with those that failed in clinical trials due to efficacy or safety concerns.Systematic review of animal studies testing MS DMTs, identified from searches in PubMed and EM-BASE. We used machine-learning methods for abstract screening and data extraction. A random ef-fect meta-analysis was fitted to the data to compare outcome effect sizes for approved vs. failed DMTs.We included 497 animal studies, covering 15 approved and 11 failed DMTs, tested in approximately 30’000 animals. DMTs were tested in a small repertoire of experimental parameters: about 86% of studies used experimental autoimmune encephalomyelitis (EAE), 80% used mice, and 76% used fe-male animals. Neither outcomes of animal studies nor testing a DMT under more diverse experimental settings, e.g., across different laboratories or animal models, were associated with successful approval. Surprisingly, 91% of animal studies were published after first-in-MS trial and 91% after official regu-latory approval.Our study underscores specific challenges in translating animal research to clinical practice, including limited experimental methods, and a potential disconnect between preclinical and clinical research. We advocate for increasing experimental variability and efforts to streamline drug development for MS to improve animal research’s relevance to patient care.\n\n\n\n\n\n\n\n\n\nFriederike Kohrs - Communities for Open Research Synthesis – accelerating the translation of evidence by integrating preclinical systematic reviews into the research pipeline\n\n\n\n\n\nCharité | BIH QUEST Center for Responsible Research\nKohrs, Friederike Elisabeth; Vojvodic, Sofija; Karmakar, Mala; Rackoll, Torsten; Bannach-Brown, Alexandra; McCann, Sarah\nOur project Communities for Open Research Synthesis (COReS) develops a targeted framework to initiate systemic change in how preclinical evidence from laboratory studies is translated into improved human health outcomes. Systematic review and meta-analysis act as an evidence-based bridge when translating scientific findings. These techniques allow us to identify what we currently know, how reliable evidence is, and where future research is needed, thereby increasing the possibility for successful translation. COReS aims for long-lasting change in how research is designed, conducted, and disseminated considering up-to-date evidence. We leverage existing community expertise and develop sustainable implementation, thereby advancing high-quality research. We employ a three-pillar approach to integrate preclinical systematic reviews into the research pipeline. Education: Comprehensive education grows awareness of the benefits of preclinical systematic review and builds capacity and methodological competence. In addition to live workshops, we have developed freely available eLearning modules. Our “train-the-trainer” programme enables qualified researchers to educate others at their institutions, effectively delivering education at scale. Infrastructure: To carry out preclinical systematic reviews, appropriate infrastructure and support is required. We build on existing software, Systematic Review Facility (SyRF), expanding to support helpdesk enquiries, and optimise user experience and documentation. We collaboratively develop new features and integrate novel automation tools into SyRF, reducing resources associated with conducting systematic reviews. Community: Forging communities to address the disconnect between primary research and evidence synthesis is instrumental. Our digital hub combines resources, tools, and support and our online open community forum facilitates sharing of standards and discussion of methodological questions, allowing for new collaborations to be formed. Partner institutions across Germany are currently piloting this blueprint for initiating communities, ensuring adaptability to different institutions and biomedical research fields. COReS creates interdisciplinary networks to address challenges of preclinical and translational research, facilitating decision-making in research prioritisation. “Please note: our results and outlook section has been submitted in the results section of the abstract submission form”\n\n\n\n\n\n\n\n\n\nMayerli Andrea Prado Rivera - Effects of early-life stress on social functioning in depression: A systematic review and meta-analysis of mouse and rat studies\n\n\n\n\n\n\nBehavioural Neuroscience, Groningen Institute for Evolutionary Life Sciences, University of Groningen,The Netherlands; (2) Department of Anaesthesiology, Pain and Palliative Care, Radboud University Medical Centre, The Netherlands\n\nPrado-Rivera, Mayerli Andrea(1); Deddens, Verena(1); Fortuin, Annemarijn(1); Wever, Kimberley E.(2); Olivier, Jocelien D.A.(1)\nAbout 5% of adult population experience depression. People that experienced early-life stress are more likely to develop depression. Increasing evidence shows that maternal stress before conception (pregestational stress) and during pregnancy (prenatal stress) also increase the risk for depression in the offspring. Depression is linked to social impairments, however, underlying mechanisms of social deficits associated with depression are poorly understood, limiting targeted treatment of these symptoms in the clinical setting. By systematically reviewing rodent studies on depression induced by early-life and maternal (prenatal and pregestational) stress, depression-related social deficits can be characterized and underlying mechanisms revealed. This critical assessment of literature will help to elucidate how early-life and maternal stress contribute to social impairments in depression and provide insights for future human studies where social deficits in depression are found to reveal important targets for therapeutics in depressed patients.To systematically analyze the effects of pregestational, prenatal and postnatal early-life stress (ELS) exposure on depression-related social behaviors in mouse and rat models.The methodology of our review has been prospectively registered in PROSPERO (#CRD42024552870). We performed a comprehensive literature search in PubMed and EMBASE, employing controlled vocabularies unique to each database for maximum sensitivity. To select relevant studies for data collection, title/abstract and full-text screening were conducted. Eligibility criteria followed the PICO structure that was used to formulate the review question. Screening of reference lists of included studies is currently ongoing to complement the comprehensive search results. Next steps include: 1) extraction of study characteristics (eg., time window of ELS manipulation, type of stressor); 2) extraction of primary outcomes of social behaviors that can be categorized into one of the following social behavioral constructs: social affiliation/attachment, social communication, or social cognition; 3) quality assessment of selected studies by using SYRCLE’s risk of bias tool for animal studies.NANA\n\n\n\n\n\n\n\n\n\nTorsten Rackoll - An interactive shiny application to support critical appraisal training in preclinical evidence synthesis\n\n\n\n\n\nBIH QUEST Center for Responsible Research, Berlin Institute of Health at Universitätsmedizin Berlin (Rackoll, Economou, McCann); Department of Anesthesiology, Radboud Institute for Health Sciences, Radboud University Medical Center, Nijmegen, The Netherlands (Weaver)\nRackoll, Torsten; Economou, Maria; Weaver, Kim; McCann, Sarah\nThe quality of synthesized evidence is a key factor that influences the validity of conclusions drawn from a systematic review. In the preclinical field, specific tools have been developed to assess methodological and reporting quality of primary evidence, and their widespread adoption in evidence synthesis is still growing. At the same time, teaching critical appraisal can be very resource-intensive, as it often requires domain-specific exposure and extensive training. To present an interactive shiny application to support critical appraisal training in preclinical evidence synthesis Motivated by the need to optimize critical appraisal training in the preclinical field, we report the development of an interactive shiny web application, based on the SYRCLE risk of bias (RoB) tool for preclinical studies (Hooijmans et al., 2014). The application is based on a self-developed flow chart incorporating guiding questions to facilitate decision making. This application aims to serve as a self-paced learning resource that allows users to work through all the steps of performing a RoB assessment of animal experiments in a user-friendly environment. The browser-based app also provides detailed information and real-life examples on the different types of biases that could affect preclinical studies, while integrating recently developed tools such as robvis (McGuinness and Higgins, 2020) to visualize the results. This application could be used as a stand-alone resource, as well as a tool to be incorporated in curricula/workshops teaching critical appraisal and (preclinical) systematic reviews. Our aim is to present the application and provide an overview of the implemented features. In addition, we thrive to facilitate an open discussion around an upgrade of the current RoB tool to incorporate experiences made since 2014.\n\n\n\n\n\n\n\n\n\nFiona Ramage - Systematic evaluation of the overlap of disease model induction procedures used and behavioural outcomes assessed in animal models of anxiety, depression, and psychosis\n\n\n\n\n\n1 Centre for Clinical Brain Sciences, University of Edinburgh, Edinburgh EH8 9YL, UK 2 Berlin Institute of Health at Charité, Universitätsmedizin Berlin, Charitéplatz 1, 10117, Berlin, Germany\nFiona Ramage1, Kaitlyn Hair1, Sean Smith1, Emma Wilson1, Alexandra Bannach-Brown2, Francesca Tinsdeall1, Charis Wong1, Emily Sena1, Malcolm Macleod1\nIn vivo psychiatry research is heterogenous with diverse disease models and behavioural assays to evaluate psychiatric symptoms The field faces challenges with synthesising a large and rapid-growing body of evidence. Historically, the psychiatric condition claiming to be modelled in an animal is defined based on context and the study authors’ intentions, but we suspect substantial overlap between procedures used to model anxiety, depression, and psychosis and behavioural assays used to evaluate these. As such, current systematic or other literature search approaches to identify preclinical studies relevant to a specific disease area (i.e. using disease-specific search terms) may be limited, and better approaches could be developed to enrich them.We aim to quantify the overlap of disease model induction procedures, therapeutic interventions, and behavioural outcomes in preclinical research claiming to model depression, anxiety, or psychosis, by observing their presence in 3 distinct disease-specific databases. We develop Systematic Online Living Evidence Summary (SOLES), curated databases using semi-automated methodologies specifically for preclinical anxiety, depression, and psychosis research to tackle these issues. We will retrieve summaries of all disease models, interventions, and behavioural outcomes featuring in each database tagged using text-mining regex-based tools, and specifically capture those featuring in more than one SOLES database. We will adopt a similar approach for model-outcome pairs and outcome-outcome pairs (where multiple outcomes are measured within a single study). We anticipate finding substantial overlap between SOLES databases for anxiety, depression, and psychosis in models, interventions, and outcomes featuring, and relationships between these. Similarities in models, interventions, and outcomes present in these historically distinct disease areas would support research efforts to integrate evidence across these disease-based siloes. Creating a database like a unified SOLES combining all three entities would enable better capture of relevant evidence for researchers in in vivo psychiatric research.\n\n\n\n\n\n\n\n\n\nChris Sena - SyRF: The Systematic Review Facility - A web-based application for managing and performing preclinical systematic reviews\n\n\n\n\n\nCAMARADES, The University of Edinburgh\nKarmakar, Mala; Bannach-Brown, Alexandra; Macleod, Malcolm; Sena, Emily; Currie, Gillian; Sena, Chris\nSystematic Review Facility (SyRF) is an online platform for conducting systematic reviews of preclinical studies. Launched in 2016, SyRF supports various systematic reviews addressing different experimental designs and research questions. It allows users to adopt emerging automated tools, supports best practices, and enables collaborative teams to screen studies independently, regardless of location.We present the key features, infrastructure, and benefits of SyRF for improving the efficiency and accuracy of systematic reviews, particularly for researchers dealing with large datasets. Our ethos is rooted in open science and transparency, with all interactions recorded and reportable. We also showcase the latest features available to users. SyRF is an open-access web application featuring a frontend user interface built with Angular, an ASP.Net Core Web API, and secure data storage in MongoDB. Its infrastructure is designed for horizontal scalability, allowing it to handle increasing demands efficiently. The user interface ensures a seamless user experience, while the robust backend and secure data storage provide reliable performance and data integrity. A typical workflow in SyRF includes: Creating a project; Configuring stages; Defining annotation questions; Uploading studies in systematic searches; Inviting users to join the project; Reviewing studies (screening, annotating, extracting quantitative data); Exporting data for analysis; Since SyRF’s launch, we have maintained a growing user base and implemented new features requested by users. The integration of a user-friendly interface with powerful backend processing capabilities allows researchers to focus on critical analysis rather than manual data handling. We present the latest features released to SyRF, updated figures for the number of users, projects supported, and the locations of scientists using SyRF.Future developments will utilise AI-driven functionality to support rapid data extraction and analysis. SyRF remains a freely available resource for the systematic review community, and we invite feedback and requests for new features.\n\n\n\n\n\n\n\n\n\nSean Smith - Systematic Online Living Evidence Summaries (SOLES): Meeting Demand for Rapid, Rigorous, and Redefined Evidence Synthesis\n\n\n\n\n\nUniversity of Edinburgh\nSmith, S. (1); Economou, E. (2), Wilson, E. (1), Bannach-Brown, A. (2), Wong, C. (2), Hair, K. (1)\nPreclinical systematic reviews are labour-intensive to conduct and often struggle to keep pace with the emergence of new evidence. For research areas with a high publication rate, there is often a lack of efficient synthesis to guide future research and inform translation. Using automated tools and machine learning techniques, we have established Systematic Online Living Evidence Summaries (SOLES) platforms across several research fields. SOLES acts as a tool for resource users to identify and interrogate existing data, facilitating further synthesis and re-use.To meet the growing demand for SOLES platforms, we aimed to develop scalable approaches. Our objectives were to fully automate the SOLES workflow, optimize the production of our web applications and create an open-source R package to facilitate the use and further development of SOLES by others.We developed a fully automated workflow, which includes database searches, removal of duplicate records, article screening for inclusion, study characteristic tagging, and web-app redeployment. We unified the relational database structure across SOLES to simplify maintenance and allow for data integration. To streamline web application development, we used modularization to create reproducible “building blocks” for individual application elements. More recently, we have been developing a system which leverages AI to extract study characteristics which our previous natural language processing method struggled to identify. Our scalable infrastructure supports over 10 SOLES projects at various development stages. Aligning our approaches has enabled the integration of multiple evidence domains, allowing for disease-agnostic interrogation and new discoveries.SOLES platforms represent a significant advancement, enabling rapid, rigorous, and redefined approaches to evidence synthesis. Our efforts ensure that researchers and other stakeholders can access and use the latest evidence efficiently, paving the way for accelerated synthesis.\n\n\n\n\n\n\n\n\n\nJulia Steitz - Development of a Systematic Online Living Evidence Summary (SOLES) for Animal Models testing Targeted Therapies against Cancer\n\n\n\n\n\nCAMARADES Berlin, QUEST Center for Responsible Research, Berlin Institute of Health at Charité (BIH), Berlin, Germany; Institute for Laboratory Animal Science, Faculty of Medicine, RWTH Aachen University, Aachen, Germany\nMcCann, Sarah; Bannach-Brown, Alexandra; Mirzaei, Yalda; Ahmadvand, Ardalan; Economou, Maria; Steitz, Julia\nCancer is a leading cause of death worldwide and new therapies are needed, necessitating testing in animal models. Although a wide variety of tumor models have been described in the literature, their limitations, as well as unsuccessful translation attempts are often not reported. Yet, choosing the right animal model for the drug to be tested and successfully translated into the clinic is critical. We will systematically review studies testing targeted therapies using preclinical tumor models. Our aim is to shed light on the animal models which have been successfully tested in cancer research and identify variables that contribute to successful translation and markers of high external validity such as FDA approval. Given the substantial number of studies potentially relevant to this topic, we are developing and validating an automated approach to categorize and prioritize studies before focusing on in-depth review of disease domains with potential for greatest impact. We will establish and validate the approach in disease domains with a manageable number of publications, to demonstrate the feasibility of extension to other tumor entities.: The results will be implemented in an interrogatable database accessed through a user-friendly online dashboard that can be used to filter studies based on study design features of interest (Systematic Online Living Evidence Summary; SOLES). The dashboard will be used to support the conduct of specific systematic reviews and highlight gaps in the literature for future research. The Cancer-SOLES platform will provide novel opportunities to identify drug and model combinations that show concordance with human outcomes but will also identify which models did not show a successful translation. With this tool, we aim to facilitate and accelerate the model selection process for preclinical cancer studies and to reduce the number of animals used in cancer research.\n\n\n\n\n\n\n\n\n\nSofija Vojvodic - Addressing External Validity in Animal Stroke Research: Systematic Review and Meta-Analysis of Sex Differences in Ischemic Models\n\n\n\n\n\nBerlin Institute of Health at Charite; Berlin Institute of Health at Charite; Berlin Institute of Health at Charite; Center for Stroke Research Charite University of Medicine; Berlin Institute of Health at Charite\nRackoll, Torsten; Shum Yee Khor, Yvonne; Celebi, Ceren; Harms, Christoph; McCann, Sarah\nIschemic stroke is a leading cause of global disability, yet its precise pathogenic mechanisms remain elusive, limiting the effectiveness of current treatments. This problem is compounded by animal models that often fail to accurately represent key patient characteristics such as health status and age. Furthermore, these models predominantly use male subjects, despite stroke affecting all genders. This male-centric focus in research means that treatments validated in these models may be ineffective or even harmful for females. Understanding sex differences in stroke is crucial for translating findings from animal models to human patients. This systematic review aims to provide a more nuanced understanding of how sex influences stroke outcomes and treatment efficacy. By examining both male and female subjects, we can uncover differences in pathophysiological pathways and treatment responses that are critical for developing effective, personalized interventions for both sexes. Our methods followed a pre-registered protocol (PROSPERO ID CRD42023495731) to investigate sex differences in stroke severity, treatment effects, and mechanisms of injury, protection, and repair. We searched for in vivo stroke studies using animals of both sexes in Embase via OVID, the Web of Science preprint collection, and Stroke-SOLES, a custom-made tool that uses machine learning to filter for animal stroke experiments. This approach yielded 4896 unique records. After title and abstract screening by at least two independent reviewers, 1396 studies were included. Full-text screening, data extraction, and risk of bias assessment have been done by two independent reviewers, with discrepancies reconciled by a third. Preliminary findings were obtained on single reviewer extractions. Normalised mean difference effect sizes were calculated, and random effects meta-analysis was applied to combine effects.Preliminary analysis showed that female animals have on average 32.5% smaller infarct volumes than males. Univariate meta-regression showed that this difference was present in young but not in aged or middle-aged animals. However, the amount of remaining heterogeneity was high. No sex differences were found in post-stroke survival rates. Most studies had unclear or high risk of bias assessments across all domains, except for selection bias where 70% of studies were at low risk of being biased by unequal baseline characteristics between sexes.Male animals exhibit larger infarct volumes compared to females, yet this does not result in higher mortality. Notably, in line with clinical observations, sex differences in stroke are influenced by age, implying a role of sex hormones in stroke pathophysiology. While various mechanisms underlying these sex differences have been suggested, further investigation is necessary to fully understand them. Furthermore, the majority of included studies are of poor quality, impeding the ability to draw reliable conclusions. As our systematic review progresses, we will supplement these preliminary findings with further investigations of factors contributing to heterogeneity, sex differences in treatment efficacy and mechanisms of stroke injury, protection and repair."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SR-SAVI Conference",
    "section": "",
    "text": "on Systematic Reviews of Studies in Animals and in VItro - Zürich, 17-18 October 2024\n\n\nYour browser does not support the video tag."
  },
  {
    "objectID": "index.html#welcome-to-the-5th-international-sr-savi-conference",
    "href": "index.html#welcome-to-the-5th-international-sr-savi-conference",
    "title": "SR-SAVI Conference",
    "section": "",
    "text": "on Systematic Reviews of Studies in Animals and in VItro - Zürich, 17-18 October 2024\n\n\nYour browser does not support the video tag."
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "SR-SAVI Conference",
    "section": "About",
    "text": "About\nA 2-day international meeting on Systematic Reviews of Animal studies and in VItro. Our priority topics for discussion include:\n\nThe integration of automation and AI in systematic reviews and meta-analyses.\nTranslational research bridging animal studies to human applications and policy implementation.\nIdentification and management of questionable research practices and potential research misconduct.\nA Reproducibility Challenge"
  },
  {
    "objectID": "index.html#sponsors",
    "href": "index.html#sponsors",
    "title": "SR-SAVI Conference",
    "section": "Sponsors",
    "text": "Sponsors\nA special thanks to our sponsors that made this conference possible:"
  },
  {
    "objectID": "index.html#thanks-to",
    "href": "index.html#thanks-to",
    "title": "SR-SAVI Conference",
    "section": "Thanks to",
    "text": "Thanks to"
  },
  {
    "objectID": "program.html",
    "href": "program.html",
    "title": "Day 1 (October 17th)",
    "section": "",
    "text": "Your browser does not support the video tag. \n\nThe conference will be held at the University of Zürich, in building RAA, Rämistrasse 59, 8001 Zürich, Aula RAA-G01, floor G\nPlease note: the program is subject to minor changes until the beginning of the conference\n\nDay 1 (October 17th)\n\n\n\n\n\n\n\n\n8:30-8:50\n\n\nRegistration and Welcome\n\n\n\n\n\n\n\n\n\n8:50-9:00\n\n\nIntroduction and Housekeeping\n\n\n\n\n\n\n\n\n\nSession 1: Translational Research Bridging Animal Studies to Human Applications and Policy Implementation\n\n\n\n\n\n\n\n\n\n9:00-9:30\n\n\nKeynote by Benjamin Ineichen\n\n\n\n\n\n\n\n\n\n9:30-10:30\n\n\nPresentations (15 minutes each):\n\n\n\n\n\n\n\n\n\n\n\nMala Karmakar: Open Data Commons for Stroke: a free community platform to share research data and facilitate synthesis\n\n\n\n\n\n\n\n\n\n\n\nCarolyne Huang: A simulation study to quantify successful translation of results from preclinical studies to human trials\n\n\n\n\n\n\n\n\n\n\n\nJoelle Jagersma: Animal models for the social, cognitive, and neurobiological impact of early-onset hearing loss: a systematic review with synthesis without meta-analysis (SWiM)\n\n\n\n\n\n\n\n\n\n\n\nCharis Wong: Selecting amantadine as the 3rd experimental arm for MND-SMART using a data-driven framework\n\n\n\n\n\n\n\n\n\n10:30-11:00\n\n\nCoffee break\n\n\n\n\n\n\n\n\n\nSession 2: Promoting Rigour and Transparency in Systematic Reviews \n\n\n\n\n\n\n\n\n\n11:00-11:30\n\n\nKeynote by David Moher\n\n\n\n\n\n\n\n\n\n11:30-12:30\n\n\nPresentations (15 minutes each):\n\n\n\n\n\n\n\n\n\n\n\nAlexandra Bannach-Brown: Barriers and enablers to conducting systematic reviews at a German University Medical Center – Findings from the “Communities for Open Research Synthesis” project\n\n\n\n\n\n\n\n\n\n\n\nAileen MacLellan: Assessing scientific rigour and 3Rs implementation in Canadian research: An investigation of animal use protocols\n\n\n\n\n\n\n\n\n\n\n\nMartijn Nolte: Better Science through More Transparency: Pilot study on stimulating transparent laboratory animal research\n\n\n\n\n\n\n\n\n\n\n\nClara Sanchez-Izquierdo Lozano: Methodological assessment of in vitro systematic reviews: a systematic review\n\n\n\n\n\n\n\n\n\n12:30-13:30\n\n\nLunch break\n\n\n\n\n\n\n\n\n\n13:30-14:00\n\n\nKeynote by Georgia Salanti\n\n\n\n\n\n\n\n\n\nReproducibility Challenge\n\n\n\n\n\n\n\n\n\n14:00-14:15\n\n\nIntroduction to the challenge by Kimberley Wever and Sarah McCann\n\n\n\n\n\n\n\n\n\n14:15-15:15\n\n\nPresentations by the challengers (15 minutes each):\n\n\n\n\n\n\n\n\n\n\n\nSofja Vojvodic and team\n\n\n\n\n\n\n\n\n\n\n\nMaria Economou and Torsten Rackoll\n\n\n\n\n\n\n\n\n\n\n\nFiona Ramage and team\n\n\n\n\n\n\n\n\n\n\n\nMatheus Gallas-Lopes and team\n\n\n\n\n\n\n\n\n\n15:15-16:00\n\n\nGeneral discussion and steps moving forward\n\n\n\n\n\n\n\n\n\n17:00 onwards\n\n\nSocial Event\n\n\n\n\n\nDay 2 (October 18th)\n\n\n\n\n\n\n\n\nSession 3: Identification and Management of Questionable Research Practices and Potential Research Misconduct\n\n\n\n\n\n\n\n\n\n9:00-9:30\n\n\nKeynote by Elisabeth Bik\n\n\n\n\n\n\n\n\n\n9:30-10:15\n\n\nPresentations (15 minutes each):\n\n\n\n\n\n\n\n\n\n\n\nKimberley Wever: Uncovering Duplicated Images in Scientific Literature - Systematic Review as a Tool for Detection\n\n\n\n\n\n\n\n\n\n\n\nOtto Kalliokoski: It is time to talk about fraudulent studies in meta-analytical evidence synthesis – learnings from a preclinical systematic review\n\n\n\n\n\n\n\n\n\n\n\nSara Steele: Underreporting in non-clinical publications: Development of the rigor assessment tool (RAT)\n\n\n\n\n\n\n\n\n\n10:15-10:45\n\n\nCoffee break\n\n\n\n\n\n\n\n\n\nSession 4: The Integration of Automation and AI in Systematic Reviews and Meta-analyses\n\n\n\n\n\n\n\n\n\n10:45-11:15\n\n\nKeynote by Kaitlyn Hair\n\n\n\n\n\n\n\n\n\n11:15-11:55\n\n\nPresentations (10 minutes each):\n\n\n\n\n\n\n\n\n\n\n\nUlf Tölch: Assessing quality criteria in publications through AI assisted pipelines\n\n\n\n\n\n\n\n\n\n\n\nAndrew Rooney: Improving workflow for evidence-based decision making in environmental health evaluations\n\n\n\n\n\n\n\n\n\n\n\nFrancesca Tinsdeall: A Comprehensive Evaluation of Stopping Rules in Technology-Assisted Review: When Have We Screened Enough?\n\n\n\n\n\n\n\n\n\n\n\nPu Yiyuan: Large Language Models in systematic review automation of Alzheimer’s research: enhancing living evidence landscape with PICO entity extraction\n\n\n\n\n\n\n\n\n\n12:05-12:35\n\n\nPanel discussion with speakers and keynote\n\n\n\n\n\n\n\n\n\n12:35-14:30\n\n\nStanding lunch and walking poster session\n\n\n\n\n\n\n\n\n\n14:30-15:00\n\n\nAwards, acknowledgements & closing by Benjamin Ineichen & organizers"
  },
  {
    "objectID": "Venue.html",
    "href": "Venue.html",
    "title": "SR-SAVI Conference",
    "section": "",
    "text": "Your browser does not support the video tag."
  },
  {
    "objectID": "Venue.html#location",
    "href": "Venue.html#location",
    "title": "SR-SAVI Conference",
    "section": "Location",
    "text": "Location\nThe conference will be held at the University of Zürich, in building RAA, Rämistrasse 59, 8001 Zürich, Aula RAA-G01, floor G"
  },
  {
    "objectID": "Venue.html#how-to-get-there",
    "href": "Venue.html#how-to-get-there",
    "title": "SR-SAVI Conference",
    "section": "How to get there",
    "text": "How to get there\nThe venue is easily accessible by public transportation. From “Zürich HB” (main train station), you can take tram line 3/bus 31 to “Neumarkt” , or tram line 6/10 to “ETH/Universitätsspital”, which is just a short walk from the building\nAlternatively, you can enjoy a scenic 15-20 minute walk from the main station to the venue. For a unique experience, consider taking the Polybahn funicular from “Central” up to “Polyterrasse,” followed by a short 5-minute walk to the building."
  },
  {
    "objectID": "Venue.html#accessibility",
    "href": "Venue.html#accessibility",
    "title": "SR-SAVI Conference",
    "section": "Accessibility",
    "text": "Accessibility\nAccessibility information of the venue can be found here."
  },
  {
    "objectID": "speakers.html",
    "href": "speakers.html",
    "title": "SR-SAVI Conference",
    "section": "",
    "text": "Your browser does not support the video tag."
  },
  {
    "objectID": "speakers.html#keynote-speakers",
    "href": "speakers.html#keynote-speakers",
    "title": "SR-SAVI Conference",
    "section": "Keynote speakers",
    "text": "Keynote speakers\nSpeakers are sorted by alphabetical order\n\n\n\n\n\n\n\n\n\n\nBio\nSession keynote\nMore\n\n\n\n\n\nElisabeth Bik Elisabeth Bik, PhD is a Dutch-American microbiologist who has worked for 15 years at Stanford University and 2 years in industry. Since 2019, she is a science integrity volunteer and consultant who scans the biomedical literature for images or other data of concern. She has found over 8,000 scientific papers, and her work resulted in over 1,200 retractions and another 1,000 corrections. For her work in science communication and exposing research misconduct, she received the 2021 John Maddox Prize.\nSession 3: Errors and Misconduct in Biomedical Research\nMore Info\n\n\n\nKaitlyn Hair Kaitlyn Hair is a post doctoral researcher funded by Alzheimer’s Research UK. With a background in Neuroscience and Psychology, she is interested in curating and evaluating the evidence from preclinical animal models of neurological diseases to inform future research and improve methodological rigour and reporting quality. She has lead the development of Systematic Online Living Evidence Summaries across a number of research domains, and developed pipelines of integrated AI tools to accelerate evidence synthesis.\nSession 4: Interpretable LLMs for Biomedical Summarisation\nMore Info\n\n\n\nBenjamin Ineichen Benjamin V. Ineichen, MD, PhD, leads the STRIDE-Lab at the Center for Reproducible Science, at University of Zurich and is dedicated to bridging preclinical and clinical research gaps, using data science and evidence synthesis. He earned his medical degree from the University of Zurich and holds a PhD in pharmacology and neuroscience from ETH Zurich. He has completed research stays at both the Karolinska Institute in Sweden and the NIH in the United States. His research focuses on the factors that drive successful drug regulatory approval, bridging animal studies and human clinical trials. His interdisciplinary team employs evidence synthesis techniques, including systematic reviews and natural language processing, with an emphasis on large language models.\nSession 1: From animal testing to regulatory approval: evidence-based approaches in drug discovery\nMore Info\n\n\n\nDavid Moher Professor Moher, a clinical epidemiologist, has spent his academic career pursuing various types of research interests including developing the evidence base for how to conduct systematic reviews and meta-analyses. Professor Moher has also developed many reporting guidelines including CONSORT 2024 and PRISMA 2020. He has also developed the evidence base for how to develop reporting guidelines. Over the last 10 years his research focus has been on the principles and practices of open science including data sharing and reproducibility. Professor Moher was elected a Fellow of the Royal Society of Canada and a Fellow of the Canadian Academy of Health Sciences.\nSession 2: “Of Mice and Men”. Optimizing the truth\nMore Info\n\n\n\nGeorgia Salanti Georgia Salanti is associate professor of Biostatistics and Epidemiology at the University of Bern. Her research focuses on methods for evidence synthesis and systematic reviews. Several of her methodological developments have been applied to answer clinical questions in mental health.\nSession 2: GALENOS - pushing the limits of methodological innovation\nMore Info"
  },
  {
    "objectID": "speakers.html#speakers-and-abstracts",
    "href": "speakers.html#speakers-and-abstracts",
    "title": "SR-SAVI Conference",
    "section": "Speakers and abstracts",
    "text": "Speakers and abstracts\n\nTalks\n\n\n\n\n\n\nAlexandra Bannach-Brown - Barriers and enablers to conducting systematic reviews at a German University Medical Center – Findings from the “Communities for Open Research Synthesis” project\n\n\n\n\n\nBerlin Institute of Health @ Charite, Berlin, Germany\nBannach-Brown, Alexandra: Kohrs, Friederike Elisabeth; Amin Tariq, Ayesha; Vojvodic, Sofija; Karmakar, Mala; Rackoll, Torsten; McCann, Sarah\nCommunities for Open Research Synthesis (COReS) develops a targeted framework to initiate systemic change in how evidence from preclinical studies is translated into improved human health outcomes. Systematic review and meta-analysis are research synthesis tools that advance high-quality research by evaluating how reliable evidence is and clearly identifying knowledge gaps, highlighting where future research is needed. We employ a three-pillar approach to integrate preclinical systematic reviews into the research pipeline and foster synthesisable primary research practices; building capacity with open-access training opportunities and comprehensive online resources for researchers and stakeholders at all experience levels (education); scaling capacity for synthesisable research and systematic review conduct by developing tools and software (infrastructure); and forging networks through interdisciplinary learning and collaboration opportunities (community). With this sub-study, we aimed to identify barriers and enablers to conducting systematic reviews and identify current practices to systematic review conduct at one of the largest European university medical centres (UMCs), Charité. We surveyed all UMC staff members (including researchers, research support staff, clinicians, and other) about their awareness of and attitudes towards systematic review. We conducted follow-up interviews with interested survey participants to examine attitudes and current practices towards systematic reviews. We further present our strategy to extend this survey to all UMCs across Germany to inform our nationwide implementation strategy. Our findings highlight specific barriers and enablers identified by multiple stakeholders when conducting systematic reviews at a European University Medical Center. We use these findings within the COReS project to develop sustainable implantation strategies to enact long-lasting change in how preclinical research is designed, conducted, and disseminated considering up-to-date evidence.\n\n\n\n\n\n\n\n\n\nCarolyne Huang - A simulation study to quantify successful translation of results from preclinical studies to human trials\n\n\n\n\n\nUniversity of Zurich\nHuang, Carolyne; Heyard, Rachel\nDrugs that show promising results in animal preclinical studies frequently fail to do the same in human clinical trials, a phenomenon known as the “translational failure”. Currently, there is no agreed-upon metric to quantify translational success between these two inherently different populations. However, there is a growing body of literature on quantifying the success of a replication of an original finding. While translation and replication are not exactly the same, the metrics developed for replication success could be useful in the translation setting.This simulation study aims to explore the behavior and characteristics of such replication success metrics under various simulation conditions designed to mimic real-world translation settings, and ultimately assess the usefulness of these metrics in defining translation success.The data-generating mechanism is based on a previously published meta-analysis assessing the effect of prenatal amino acid supplementation on maternal blood pressure. The data includes both animal and human studies investigating the same treatment and outcome, which ensures the plausibility of our data-generation process. Animal and human studies are simulated under different conditions: (1) null and alternative animal and human hypotheses, and (2) powered vs. non-powered animal studies. Additionally, the study investigates various criteria to continue from an animal experiment to a human study, e.g., a human study is performed only if a meta-analysis of three independent animal studies demonstrates a significant beneficial effect. The previously developed replication success metrics are applied to the results of the simulated animal and human studies. From this, we can calculate the share of successful translations under each of the simulation conditions in order to determine which metric performs well in which conditions. We adhered to best practices when designing our simulation study, including pre-registering a study protocol on the Open Science Framework before running the simulation. –\n\n\n\n\n\n\n\n\n\nJoelle Jagersma - Animal models for the social, cognitive, and neurobiological impact of early-onset hearing loss: a systematic review with synthesis without meta-analysis (SWiM)\n\n\n\n\n\n1 Department of Otorhinolaryngology and Head/Neck Surgery, University of Groningen, University Medical Center Groningen, Groningen, The Netherlands. 2 Neurobiology, Groningen Institute for Evolutionary Life Sciences, University of Groningen, Groningen, The Netherlands. 3 Dept. of Anaesthesiology, Pain and Palliative Medicine, Radboud University Medical Center, Nijmegen, The Netherlands.\nPrado Rivera, Mayerli 2; Deddens, Verena 2; Wever, Kimberley E. 3; Olivier, Jocelien D. A. 2; Pyott, Sonja J 1\nExtensive research indicates that hearing loss in children can lead to impairments in social and cognitive (learning and memory) development. To reduce these deficits in children, novel treatment options are needed. However, it is still unknown how exactly hearing loss results in diminished social and cognitive development. Several animal models have been developed to address this problem, which vary widely in terms of hearing loss onset and severity, the induction method, and outcomes (e.g. assessments of social and cognitive behavior and involved neurobiological structures). Given this high level of variability between studies and their findings, a systematic review is essential and timely. This systematic review aims to synthesize findings from animal studies on early onset hearing loss, with a focus on both investigating its impact on social and cognitive behaviors and identifying the associated underlying neurobiological mechanisms.The review methodology was prospectively registered in PROSPERO (ID: CRD42024515848) and adhered to SYRCLE’s systematic review protocol for animal intervention studies (de Vries et al., 2015). A comprehensive search was performed in PubMed and Embase to identify animal models with early onset hearing loss. The complete search strategy encompassed the search components “animals” (Hooijmans et al., 2010), “hearing loss”, and “social or cognitive behaviors”. Screening of papers occurred largely manually but was supported by artificial intelligence. Outcome parameters were categorized as cognitive, social or vocal behavior, or as neurobiological outcomes. Synthesis of the data occurred though synthesis without meta-analysis (SWiM). (Results & Conclusion) A wide variety of animal models has been captured in the current review. Synthesis of outcome parameters is ongoing, but aims to highlight gaps in current research. The outcomes of this research will guide future animal studies towards targeted investigations of potential treatments against the negative effects of hearing loss on the social and cognitive domains.(see section above)\n\n\n\n\n\n\n\n\n\nOtto Kalliokoski - It is time to talk about fraudulent studies in meta-analytical evidence synthesis – learnings from a preclinical systematic review\n\n\n\n\n\nDepartment of Experimental Medicine, University of Copenhagen\nBerrío, Jenny; Kalliokoski, Otto\nOur current best practices for the conduct of systematic reviews leaves our evidence synthesis vulnerable to the influence of fraudulent papers. Whereas we have, for example, methods for assessing the influence of publication bias and checklists for quality of reporting, we have virtually no methods for assessing the actual veracity of the information in a study. This is a problem since we are learning that the number of fraudulent studies in biomedical science is far higher than previously suspected. What happens to the evidence gathered in a systematic review when fraudulent studies are included? In a preclinical systematic review concerning a popular model for studying depression in rats, we encountered numerous studies featuring problematic images. Some of these image issues were very difficult to explain as something other than the result of outright falsification or fabrication. Our objective thus became to estimate how common potentially fraudulent papers are by using papers with this type of image issues as a proxy, and to find out how they influence the findings of a preclinical systematic review. While carrying out full text screenings we chose to record the number of studies with problematic images and to characterize the types of issues we encountered. Moreover, we obtained journal and paper level meta-data. We then carried out a sensitivity analysis using the ten studies with problematic images that were included, post-screenings, in our review. We gauged their influence on the synthesized effect size and compared how they fared with respect to risk of bias and quality of reporting metrics.We screened 1,035 papers, where approximately half (57%) contained images we could analyze. Of the papers that we were able to assess, 19% (112 studies) contained problematic images. It is furthermore our assessment that a majority of these could not easily be explained as honest mistakes, and in quite a few cases, we could point to outright falsification or fabrication in the images. Basic bibliometrics like journal impact factor or number of citations to a paper could not be used to distinguish problematic papers. Standardized check lists for quality of reporting and risks of bias were similarly unhelpful in identifying potentially fraudulent papers. Alarmingly, the papers with problematic images seemed to produce higher effect estimates, skewing our systematic review results significantly. The lack of a consensus on how to deal with problematic papers in systematic reviews is a problem. Currently, Cochrane recommends removing papers from reviews only if they have been retracted or if it can be clearly shown that the data is somehow untrue. Following these types of recommendations are not sufficient to combat the influx of fraudulent data. If we do not develop better safeguards for excluding potentially fraudulent studies in our evidence synthesis methods, systematic reviews will quickly lose their value. It is time we have an open conversation on how we want to address the problems these types of studies pose.\n\n\n\n\n\n\n\n\n\nMala Karmakar - Open Data Commons for Stroke: a free community platform to share research data and facilitate synthesis\n\n\n\n\n\nNA\nSarah McCann, Alexandra Bannach-Brown, Sofija Vojvodic, Torsten Rackoll, Mala Karmakar\nDespite efforts to promote open data sharing, uptake remains limited in biomedical research, and shared data is often difficult to locate and reuse. This is particularly challenging for evidence synthesis, where locating relevant data can be time-consuming and ineffective. Furthermore, many null or negative results remain unpublished, leading to skewed interpretations and research waste.The Open Data Commons (ODC) aims to address these challenges by providing a cloud-based, community-driven platform for sharing, managing and publishing primary research data. It supports FAIR data principles (Findable, Accessible, Interoperable, Reusable) and facilitates evidence synthesis in translational biomedicine. This work aims to develop ODC-Stroke, a platform tailored to preclinical ischaemic stroke research.ODC-Stroke offers secure login with varied permissions for data uploading, sharing, and publishing. Preclinical stroke researchers can control data visibility, and all published datasets receive DOIs for citation and reuse. The platform is optimized for single and multi-laboratory studies. Further, ODC-Stroke allows evidence synthesis to incorporate unpublished data, which expands the scope and reliability of systematic reviews, addressing publication bias and supporting more comprehensive and sophisticated analyses. ODC-Stroke is developed through collaboration with preclinical stroke researchers to co-create a network to develop common data elements (CDEs) and integrate primary data collection with evidence synthesis pipelines. This ensures data interoperability, reusability, and more effective evidence synthesis across studies.ODC-Stroke provides a robust resource for sharing curated data, promoting collaboration, and supporting reproducibility. By offering access to individual subject data and promoting common data elements, ODC-Stroke can enhance the efficiency of systematic reviews and reduce publication bias, thereby improving data management and research integrity.\n\n\n\n\n\n\n\n\n\nAileen MacLellan - Assessing scientific rigour and 3Rs implementation in Canadian research: An investigation of animal use protocols\n\n\n\n\n\nOttawa Hospital Research Institute, University of Ottawa\nAvey, Marc; Fergusson, Dean; Lalu, Manoj\nEthical review of animal experiments is a potentially powerful mechanism for enhancing rigour and implementation of the 3Rs (replacement, reduction, refinement). However, previous assessments have revealed high risk of bias in animal use protocols, and an incomplete understanding of the 3Rs within ethical review committees. In Canada, reporting within animal use protocols has never been investigated. We therefore sought to assess current information provided to ethical review committees to identify areas for improvement. In partnership with Canada’s oversight body for animal science, the Canadian Council on Animal Care (CCAC), we are conducting a cross-sectional study of approved animal use protocols to characterise reporting of 1) rigorous methodology (randomization, blinding, sample size calculation, planned data analysis); and 2) the 3Rs. In coordination with the CCAC, a request for submission of animal use protocols was sent to 35 academic institutions. The last three mouse and three rat protocols approved prior to January 1, 2024 for minimal, low, moderate and severe stress categories of invasiveness, in both basic and translational research were requested from each academic institution (n=48 protocols/institution). Screening and data extraction were performed in duplicate by two independent reviewers.Fifteen institutions participated (43%), submitting 300 protocols (mice n=184, rats n=116). Data extraction and analyses are ongoing. Preliminary assessments of 142 protocols show reporting of blinding in 4% of protocols, randomization in 14%, sample size calculation in 37%, and planned data analysis in 20%. Efforts to replace and reduce animal use in experiments were reported in 39% and 59% of protocols, respectively; and refinements were reported in 20%. Although incomplete reporting of rigour and the 3Rs was common, understanding variation in these areas is critical for improvement. Our study will lay essential groundwork for ‘evidence-informing’ updates to CCAC policy, and support for researchers and ethical review committees.\n\n\n\n\n\n\n\n\n\nMartijn Nolte - Better Science through More Transparency: Pilot study on stimulating transparent laboratory animal research\n\n\n\n\n\nZonMw\nMenon, Julia; De Waard, Bas; Ritskes-Hoitinga, Merel\nIn 2019 , the Dutch House of Representatives passed a motion asking the government to investigate ways to increase the transparency and quality of animal research. Based on this motion, the Ministry of Education, Culture, and Science assigned ZonMw, the largest funder of biomedical research in The Netherlands, to investigate the impact on the research practice of several transparency methods, including systematic reviews. This pilot study aimed to address how researchers and other stakeholders perceive various transparency methods, what hurdles exist in applying these methods, and the feasibility of their effective implementation. Concerning systematic reviews, the main question was whether systematic reviews should be made a prerequisite, for instance for obtaining ethical approval to perform animal experiments.Researchers and stakeholders involved in biomedical research were asked through online questionnaires and semi-structured interviews about their experiences and perspectives regarding these transparency methods: Preregistration, Data management plans and FAIR data, ARRIVE guidelines, Open access publishing and Systematic reviews. Interviewees acknowledged the value of systematic reviews but deemed them impractical due to their time-consuming nature, high demand in terms of skills and cost, and bureaucratic hurdles. Alternative approaches consider demanding them in specific situations that would benefit the field or using a systematized approach to better justify chosen animal models in ethical applications. Existing funding initiatives supporting systematic reviews are deemed valuable and encouraged to be sustained.Systematic reviews are considered valuable and could be promoted in certain contexts, but having them as a requirement is not yet feasible. A separate study would be of value to assess when and how such reviews should be applied, how they should be promoted, or made compulsory. Moreover, teaching the methodology of systematic reviews in academic bachelor or master courses is considered highly valuable to prepare the next generation of scientists to perform such reviews.\n\n\n\n\n\n\n\n\n\nYiyuan Pu - Large Language Models in systematic review automation of Alzheimer’s research: enhancing living evidence landscape with PICO entity extraction\n\n\n\n\n\nSchool of Computing and Information Systems, The University of Melbourne; Centre for Clinical Brain Sciences, The University of Edinburgh; School of Computing Technologies, RMIT University; School of Computing and Information Systems, The University of Melbourne; Centre for Clinical Brain Sciences, The University of Edinburgh; School of Computing Technologies, RMIT University\nYiyuan, Pu; Kaitlyn, Hair; Daniel, Beck; Mike, Conway; Malcolm, MacLeod; Karin, Verspoor\nAD-SOLES (Systematic Online Living Evidence Summary of Alzheimer’s Disease Research) conducts living systematic reviews for preclinical Alzheimer’s research. Summaries of existing AD research are abstracted as PICO elements (Population, Intervention, Comparator, and Outcome), providing the latest combinations of models, treatments, and outcome measures. A standard method in automating PICO extraction is to apply a dictionary compiled from a set of regular expression (regex) patterns in literature. We explored improving the regex performance of intervention extraction with Large Language Model-based (LLM-based) filtering in AD-SOLES. We aim to extend the LLM-based filtering method from intervention extraction alone to all PICO elements in preclinical AD studies. For automatically identifying PICO elements, we ​​followed a two-stage filtering method in the intervention extraction of AD studies. We used a Pre-trained Language Model (PLM) to filter false positives obtained from regexes. Precision errors arising from regex-based methods were mainly due to a lack of context: any entity that matched a regex would be recognized as an intervention. We hypothesized that a PLM can contextualize entity context and filter them out if appropriate, without undermining recall. Preliminary results on intervention extraction show the two-stage filtering outperforms strong baselines, including standalone use of LLMs. For intervention extraction, a Regex-based method achieved an F1 score of 32%, and ChatGPT and GPT-4 with zero-shot learning achieved F1 scores of 29% and 27% respectively. In the Regex+ChatGPT (three-shot) scenario, the model achieved the highest F1 of 50%. Experiments of other PICO elements are in progress.PICO entity extraction with LLM-based two-stage filtering leads to more reflective summaries of Alzheimer’s studies, supporting literature-based discovery in the future. This further helps experts prioritize treatments for clinical experiments and discover drug combinations for symptoms.\n\n\n\n\n\n\n\n\n\nAndrew Rooney - Improving workflow for evidence-based decision making in environmental health evaluations\n\n\n\n\n\nDivision of Translational Toxicology (DTT), National Institute of Environmental Health Sciences (NIEHS), National Institutes of Health (NIH), Research Triangle Park, NC, USA\nWalker, Vickie\nSystematic review methods provide objectivity and transparency to the process of identifying, critically assessing, and synthesizing scientific evidence to answer environmental questions and guide public health decisions. Although, there have been significant advances in artificial intelligence (AI) and information processing, human health assessments of environmental exposures are largely developed with manual procedures. The construction of a streamlined workflow for literature-based assessments that leverages automation and AI is crucial for reducing the time and resource demands of the traditional systematic review approach. By leveraging AI and automation, the Division of Translational Toxicology’s (DTT) at the National Institute of Environmental Health Sciences enhanced assessment workflow aims to improve efficiency and accuracy while maintaining the rigorous standards of systematic review methodologies. This presentation outlines an enhanced workflow incorporating AI tools and human-in-the-loop procedures for systematic reviews and systematic evidence maps to support the accuracy necessary for public health decisions and the capacity to handle large datasets and facilitate the collection of complex information across environmental health science literature. The literature screen and extraction steps are some of the most time-consuming steps (~30% of total review time) and impactful targets for automation, particularly for environmental health questions, given the breadth of study designs and endpoints represented. By automating repetitive tasks, researchers can focus on more critical aspects of the review, such as interpreting results and synthesizing the evidence to reach conclusions. DTT’s workflow also supports transparency and reproducibility by providing clear documentation, interactive figures, and standardized procedures for each stage of the process. In this work, we present a framework that demonstrates the potential of AI and automation to significantly reduce level of effort for systematic reviews and remove barriers to their use and accessibility ensuring that decision-making is both timely and evidence based.\n\n\n\n\n\n\n\n\n\nClara Sanchez-Izquierdo Lozano - Methodological assessment of in vitro systematic reviews: a systematic review\n\n\n\n\n\nCentre for Clinical Brain Sciences, University of Edinburgh, Edinburgh EH8 9YL, UK; Berlin Institute of Health at Charité, Universitätsmedizin Berlin, Charitéplatz 1, 10117, Berlin, Germany; Sheffield Institute for Translational Neuroscience, University of Sheffield, Sheffield, S10 2HQ, UK; Clinical Epidemiology Program, Blueprint Translational Research Group, Ottawa Hospital Research Institute, Ottawa, Ontario, Canada\nSanchez-Izquierdo Lozano, Clara; Hair, Kaitlyn; Smith, Sean; Arroyo Araujo, Maria; McColl, Barry; McCann, Sarah; Livesey, Matthew; Lalu, Manoj; Sena, Emily; Malcolm, Macleod\nIn vitro research is an integral component of understanding disease, furthering drug development and addressing the 3Rs (replacement, reduction and refinement) of in vivo animal models. Systematic reviews provide a comprehensive summary of evidence and preclinical systematic reviews are crucial in translation of preclinical results to clinical settings. Systematic review protocol templates exist for clinical and preclinical in vivo systematic reviews. In vitro research has unique aspects, such as various cell line or tissue culture models, that are not shared with clinical research or preclinical in vivo research, therefore systematic review approaches used in those contexts are not appropriate or effective and must be adapted to the unique domain of in vitro studies. Currently, no such template exists for in vitro systematic reviews which can have huge consequences on the quality of in vitro systematic reviews and subsequently, a negative impact on the preclinical to clinical translation.We aim to perform a systematic review of all published in vitro systematic reviews to identify key variables in their guidance, methodologies and conduct to inform the development of an infrastructure for performing in vitro systematic reviews. Having a developed protocol will provide a robust outline of how best to conduct such reviews and thus improve their reproducibility and rigour.We will search PubMed, SCOPUS and Web of Science (ISI). Our search strategy will include two main components: (1) terms related to in vitro and (2) terms related to systematic reviews or meta-analyses. ASySD will be used to deduplicate results and SyRF will be used subsequently for screening and data extraction. Study characteristics extracted will be related to reporting quality and tools employed to conduct the in vitro systematic reviews. From this, we will curate a “long-list” of potential in vitro systematic review methodologies and perform a Delphi approach with corresponding authors from the identified in vitro systematic reviews and our international advisory board of experts in the field. Each step of the systematic review process will be assessed for the most appropriate methodological option to create an agreed infrastructure for conducting in vitro systematic reviews.Still ongoingStill ongoing\n\n\n\n\n\n\n\n\n\nSara Steele - Underreporting in non-clinical publications: Development of the rigor assessment tool (RAT)\n\n\n\n\n\nKU Leuven and Johnson & Johnson\nLavrijssen Tom; Steckler, Thomas\nThe failure rate in drug development is as high as 90% for drug candidates reaching phase I clinical trials and even higher when drug candidates from the preclinical phase are considered. The problem is multifold with one of them being issues with internal and external validity of non-clinical studies, which is in part, reflected by studies reporting on the difficulty to reproduce published research findings. A strategy to increase internal validity is lowering the risk of bias by adherence to rigorous experimental design, both for internally and externally generated data. We developed the “Rigor Assessment Tool”, an advanced data driven methodology to predict research rigor-related risks associated with a potential external business partner, based on an analysis of past scientific publications from that research unit. We explored the standards of reporting in non-clinical publications, developed an information extraction tool based on expert opinions and validated the information provided in articles. Further analyses are ongoing, but eventually we should have a full working tool that can, among other things, guide decisions when planning to engage with external partners, be used to further support the prioritization of audit planning in preclinical QA and address the issue of poor reproducibility of published data. Eventually, this tool might help to decrease the failure rate in drug development.\n\n\n\n\n\n\n\n\n\nFrancesca Tinsdeall - A Comprehensive Evaluation of Stopping Rules in Technology-Assisted Review: When Have We Screened Enough?\n\n\n\n\n\nCentre for Clinical Brain Sciences, University of Edinburgh\nTinsdeall, Francesca; Macleod, Malcolm; Callaghan, Max; Stevenson, Mark; O’Mara Eves, Alison; Thomas, James\nSystematic reviews aim to identify research articles relevant to a review question. Screening articles for inclusion is time-consuming, especially when search strings yield large volumes. Technology-assisted review (TAR) employs a classification model trained via active learning to rank articles by relevance, which determines their order of presentation for human screening. This ‘prioritised screening’ may reduce time spent reviewing irrelevant articles and is commonly used in clinical reviews and legal eDiscovery. However, the absence of well-validated tools for determining when to stop reviewing the ranked list whilst maintaining desired recall often forces researchers to review all articles, obviating the efficiency gains of TAR. TAR stopping rules are designed to determine when desired recall has been met and human screening can stop. To date, there has been no thorough evaluation of these rules across different systematic review contexts. This study will comprehensively assess the accuracy and reliability of available stopping rules across various contexts and ranking algorithms.This study will review and then evaluate stopping rules applicable to the systematic review process. Evaluation metrics will prioritise high recall and will focus on reliability and confidence in estimated stopping points. The simulation datasets used will include clinical and preclinical systematic reviews. Subgroup analyses will consider the classification model, effectiveness of prioritisation, review context, and dataset characteristics. This research will provide empirical evidence on the efficacy and reliability of TAR stopping rules and highlight context-specific factors which should guide the choice of stopping rule used for a particular screening task. Clearer guidance on selecting and using stopping rules within the TAR framework will enable researchers to utilise TAR more effectively, reducing human time and effort without compromising review quality. The results of this work will enhance decision-making in the design of both living and non-living systematic review methodologies.\n\n\n\n\n\n\n\n\n\nUlf Tölch - The future of Systematic Online Living Evidence Summaries (SOLES): emerging trends and challenges in automating evidence synthesis\n\n\n\n\n\nCharité | BIH QUEST Center for Responsible Research\nLarge language models carry the promise to support evidence synthesis with their probabilistic representations of human research artefacts, particularly written text. Here, we explore the capability of cloud based commercial large language models to evaluate published experimental papers from a broad range of fields. We compare LLM performance (same responses as human reviewers) across different architectures and pipelines on established quality criteria for scientific publications. We show that easy tasks can be achieved with almost the same accuracy of human reviewers. With increasing assessment difficulty accuracy levels drop and additional reconciliation is needed. We present guidance how this can be achieved and make suggestion for next steps.\n\n\n\n\n\n\n\n\n\nKimberley Wever - Uncovering Duplicated Images in Scientific Literature - Systematic Review as a Tool for Detection\n\n\n\n\n\nRadboud University Medical Center\nAquarius, Rene; van de Voort, Merel; Reesink, Manon; Wever, Kimberley E.\nWhile performing a systematic review of preclinical evidence for interventions against early brain injury after subarachnoid hemorrhage, we came across multiple cases of image manipulation and duplication in the included publications.To quantify and characterize image duplication and manipulation in the publications included in this systematic review.After screening for eligibility, 612 publications were included in the systematic review. For each publication, we used ImageTwin (AI driven software) to detect image duplication within each publications, as well as between each publication and the ImageTwin database of ~50 million scientific images. We also assessed image duplication and manipulation by eye. Furthermore, we reviewed whether the publication had previously been 1) reported on PubPeer; 2) retracted or 3)corrected using an erratum / corrigendum.We found duplicated images in 179 out of the included 612 publications (29.2%). We found that 95 publications contained overlapping or duplicated images within a single figure, 34 showed overlaps or duplications between figures within the publication, and 65 publications contained figures which overlapped with, or were duplicates from different publications. When assessing the journals in which these problematic studies were published, we found that all major (biomedical) publishers were represented.Image manipulation and duplication can pose a significant threat to our confidence in an evidence base, but their prevalence is largely unknown. Systematic reviews provide a unique opportunity to identify duplicated images, especially between studies in a specific field of research. Our current assessment proves that the quality of the body of evidence is compromised in this field, which has negative consequences for data synthesis.\n\n\n\n\n\n\n\n\n\nCharis Wong - Selecting amantadine as the 3rd experimental arm for MND-SMART using a data-driven framework\n\n\n\n\n\nCentre for Clinical Brain Sciences, University of Edinburgh.\nWong, Charis; Cardinali, Alessandra; Liao, Jing; Selvaraj, Bhuvaneish T.; Baxter, Paul; Carter, Roderick N.; Longden, James; Graham, Rebecca E.; Dakin, Rachel S.; Pal, Suvankar; Chataway, Jeremy; Swingler, Robert; Hardingham, Giles E.; Carragher, Neil; Chandran, Siddharthan; Macleod, Malcolm R.\nDespite decades of clinical trials, effective disease modifying treatment options for motor neuron disease (MND) remain limited. There is a pressing need to identify effective disease modifying treatments. Motor Neuron Disease-Systematic Multi-Arm Adaptive Randomised Trial (MND-SMART; ClinicalTrials.gov number: NCT04302870) is a multi-arm multi-stage, adaptive platform trial testing a pipeline of candidate drugs.Building upon systematic reviews to inform initial drug selection, we aimed to develop and implement the Systematic Living Evidence for Clinical Trials (SyLECT) framework, a modular, systematic, framework using diverse data to inform ongoing selection by expert panel.We gathered, synthesised, integrated and reported evidence from different domains to identify, evaluate, and prioritise candidate drugs. Domains included: published literature through Repurposing Living Systematic Review-Motor Neuron Disease (ReLiSyR-MND), a machine learning assisted systematic review of clinical literature of MND and othe neurodegenerative diseases which may share similar pathways, animal in vivo and in vitro literature of MND and frontotemporal dementia; in vitro high throughput drug screening; pathway and network analysis; and drug, chemical and clinical trial registry databases.We identified candidate drugs (ReLiSyR: 303, drug screening: 287, network analysis: 1144). We longlisted 49 drugs and synthesised further evidence across domains. We shortlisted 9 drugs and selected amantadine for evaluation in MND-SMART. Amantadine showed good efficacy and safety across 59 clinical publications, reduced TDP-43 aggregates on in vitro screening and was predicted to be active on multiple targets associated with MND. Amantadine was added as the third experimental arm of MND-SMART in April 2023.We demonstrated the feasibility and synergistic benefits of a systematic, multimodal, data-driven framework to inform drug selection for MND clinical trials, with potential for application across other disease areas.\n\n\n\n\n\nPosters\n\n\n\n\n\n\nJuliana Bolzan - An overview of protocols in Pharmacology registered at PROSPERO: Are there systematic reviews and meta-analyses synthesizing pharmacological interventions?\n\n\n\n\n\nDepartment of Physiological Sciences, Center of Biological Sciences, Federal University of Santa Catarina (UFSC)\nBolzan, Juliana Aparecida; Lino de Oliveira, Cilene.\nPharmacological evidence is crucial for translational research, drug discovery, and development. Pharmacologists can synthesize the available information, increasing the validity of conclusions in individual studies and identifying gaps using systematic reviews (SR) and meta-analyses (MA). However, SRMA is time-consuming, requiring reviewers’ knowledge and skills, which may discourage pharmacologists from conducting them. Here, the aim is to investigate whether and how SRMAs are being conducted in Pharmacology. For this, an umbrella overview was planned, preregistered (https://osf.io/df3kg), and carried out as follows: 1- searches for SR protocols at the PROSPERO repository; 2- screening to include protocols with any population, pharmacological intervention, comparison, and outcome; 3- extraction of data on authors identification, protocol stage, analytical and updating plans.From 1.744 protocols retrieved, 232 were included after screening (146 planned to make an MA, 38 SRMA were complete or published, and none planned for updating). “All animals” were the most frequent population (n=88) followed by rodents (n=42), rats and/or mice (n=24), or rats only (n=14). “Non-human animals”, “only mammals”, in vivo, in vitro and/or ex vivo models were less frequent (n&lt;10). The interventions were antibiotics (n=23), cannabinoids (n=20), antidiabetics (n=19), antineoplastic drugs (n=16), antidepressants (n=15), and others (n≤10: analgesics, anti-inflammatories, anesthetics, antihypertensives, statins, anthelmintics, psychostimulants, immunosuppressants, neuroprotective or anxiolytic agents). The more frequent outcomes were scores for neuropsychiatric disorders (n=40), followed by cardiovascular disorders (n=28), infections (n=20), neoplasms (n=18), pain disorders (n=15), endocrine disorders (n=13), inflammatory and neurodegenerative disorders (n=11). Outcomes of other modeled conditions were less common (n&lt;10, bone disorders, injuries, lung disorders, wound healing, cartilage damage, renal disorders, toxicity, orthodontic treatment, and atopic dermatitis).Despite the possible challenges and difficulties, pharmacologists of all fields are interested in conducting SRMAs. In the next few years many SRMA in Pharmacology are expected to be published. Nevertheless, obsolescence seems risky because no plans for updating were found.\n\n\n\n\n\n\n\n\n\nJessica Cait - The impact of social isolation on laboratory rodent health and data replicability: a systematic review and meta-analysis\n\n\n\n\n\nUniversity of Guelph & The Canadian Council on Animal Care\nCait, Jessica; Avey, Marc T.; Mason, GJ\nOver 120 million mice and rats are used in research globally each year, many of which are isolated in barren shoebox-sized cages that are poor for welfare. In humans, chronic stress increases disease susceptibility and reduces lifespans. Our previous meta-analysis showed that, compared to those in larger cages equipped with resources that allow the expression of natural behaviour, rodents in conventional cages (small and relatively barren) are more susceptible to stress-sensitive diseases (anxiety, cancer, cardiovascular disease, depression, stroke) and have shortened lifespans. Further, meta-analyses of statistical interactions between housing conditions and disease modifiers (e.g., therapeutic drugs) revealed that these effects can alter experimental results, impacting data replicability. We aim to build on our previous work on barren cages, investigating similar chronic stress effects in individually housed rodents. We hypothesize that poor welfare from social isolation harms animal health and changes research results, impacting data replicability.We searched five databases (Ovid, CABI, Web of Science, Proquest, SCOPUS) on May 26, 2024. 2,384 titles and abstracts were screened in duplicate for eligibility (published in English, using mice or rats, and using social isolation as an intervention), and full-text screening of 375 articles is underway. Random effects meta-analyses (including meta-analyses of statistical interactions) will be conducted to test hypotheses. Risk of bias will be assessed using SYRCLE’s RoB tool.Available in October.Results will help us understand how social isolation impacts laboratory rodents’ wellbeing and address whether isolation can alter experimental conclusions, thus reducing the replicability of animal-based research. These data, combined with previous work on rodent housing, will allow us to assess the relevance of welfare as a biological variable that should be considered when conducting in vivo studies.\n\n\n\n\n\n\n\n\n\nMaria Economou - Identifying and addressing challenges in automating evidence synthesis of increasingly large datasets\n\n\n\n\n\n1 CAMARADES Berlin, QUEST Center for Responsible Research, Berlin Institute of Health at Charité (BIH), Berlin, Germany; 2 Institute for Laboratory Animal Science, Faculty of Medicine, RWTH Aachen University, Aachen, Germany ; 3 Centre for Clinical Brain Sciences, University of Edinburgh, Edinburgh, UK\nEconomou, Maria1; Mirzaei, Yalda2; Ahmadvand, Ardalan2; Hair, Kaitlyn 3; Smith, Sean3; Steitz, Julia2 ; McCann, Sarah1; Bannach-Brown, Alexandra1\nAs synthesizing rapidly increasing bodies of evidence becomes a priority, methodological advances are needed to expedite systematic review of published literature. Systematic Online Living Evidence Summaries (SOLES) are one such novel approach to streamline the key stages of evidence synthesis, incorporating automated processes to search for, categorize, summarize and visualize research findings. Addressing the challenges of automating synthesis of large datasets is an important issue, especially considering the skyrocketing number of scientific publications in biomedicine. We aim to describe the surfacing challenges associated with applying automation tools on large bibliographic datasets and identify strategies for improvement.This work is done in the context of developing Cancer-SOLES, a workflow designed to facilitate the up-to-date evaluation and synthesis of studies testing small molecule therapies in animal models of cancer. Challenges at each stage of the workflow are considered, including hitting rate limits in weekly literature searches via application programming interfaces, large-scale deduplication, machine-assisted screening of records in batches, substantive metadata retrieval, bulk annotation of study characteristics, and the presentation and loading times of summary tables and visualizations in an online dashboard. Initial searches for Cancer-SOLES across four databases yielded over 1.3 million potentially relevant articles. This significantly impacted automated approaches. For instance, current programming tools for deduplication and citation screening are limited in processing smaller subsets of data at once. These constraints could lead to downstream challenges such as the ineffective removal of duplicate records in very large datasets or reducing screening accuracy. Understanding the obstacles that large datasets pose on automating key steps of evidence synthesis will allow us to identify approaches to effectively improve our current tool workflow, both in terms of accuracy and performance, as well as computational efficiency. These insights are timely and relevant as automation becomes an integral part of synthesizing rapidly emerging research output.\n\n\n\n\n\n\n\n\n\nMatheus Gallas-Lopes - Ten years of unpredictable chronic stress research in zebrafish: a systematic review and meta-analysis\n\n\n\n\n\nPharmacology Department, Universidade Federal do Rio Grande do Sul\nGallas-Lopes, Matheus; Bastos, Leonardo M.; Benvenutti, Radharani; Panzenhagen, Alana C.; Piato, Angelo; Herrmann, Ana P.\nZebrafish (Danio rerio) are increasingly used to study the neurobehavioral effects of stress. The first study on unpredictable chronic stress (UCS) in zebrafish was published just over a decade ago, adapted from rodent protocols. However, subsequent studies have yielded inconsistent results.This study aimed to evaluate the effects of UCS on zebrafish behavior and relevant biomarkers through a systematic review and meta-analysis.We conducted a comprehensive literature search across three databases (PubMed, Scopus, and Web of Science) using a two-step screening process with defined inclusion and exclusion criteria. Data extracted from qualified studies (n=38) included qualitative and quantitative information, along with a risk-of-bias assessment. For meta-analyses, the outcomes were grouped into the following categories: anxiety/fear behavior, locomotor function, social behavior, and cortisol levels.UCS exposure increased anxiety/fear behaviors (SMD 1.09, 95%CI [0.50;1.6]) and cortisol levels (0.66, [0.06;1.25]) while decreasing locomotion (−0.56, [−1.02;−0.10]). Social behavior, however, did not show a statistically significant overall effect (−0.30, [−0.77;0.17]). Despite a substantial number of studies included, high heterogeneity and methodological/reporting issues identified during the risk-of-bias assessment raised concerns about the internal validity of individual studies and the overall generalizability of this model. Interestingly, subgroup analysis revealed that stress regimens exceeding a week significantly impact anxiety, movement, and cortisol levels, while protocols lasting up to 7 days do not. This suggests a milder stress response for shorter durations and highlights the importance of protocol duration in zebrafish chronic stress studies.This review emphasizes the need for well-designed experiments and standardized stress protocols to understand the impact of UCS on various behavioral aspects of zebrafish. Future studies should employ robust methodologies and transparent reporting to strengthen the zebrafish model for chronic stress research.\n\n\n\n\n\n\n\n\n\nBenjamin Ineichen - Key experimental parameters from animal studies are not associated with successful animal-to-human translation in multiple sclerosis drug development – systematic review and meta-analysis\n\n\n\n\n\nUniversity of Zurich\nBerg, Ingrid; Härvelid, Pia; Zürrer, Wolfgang Emanuel; Rosso, Marianna; Reich, Daniel Salo; Ineichen, Benjamin Victor\nDespite successes in multiple sclerosis (MS) drug development, the effectiveness of animal studies in predicting successful bench-to-bedside translation is uncertain. Our goal was to identify predictors of successful animal-to-human translation for MS by systematically comparing animal studies of ap-proved disease-modifying therapies (DMTs) with those that failed in clinical trials due to efficacy or safety concerns.Systematic review of animal studies testing MS DMTs, identified from searches in PubMed and EM-BASE. We used machine-learning methods for abstract screening and data extraction. A random ef-fect meta-analysis was fitted to the data to compare outcome effect sizes for approved vs. failed DMTs.We included 497 animal studies, covering 15 approved and 11 failed DMTs, tested in approximately 30’000 animals. DMTs were tested in a small repertoire of experimental parameters: about 86% of studies used experimental autoimmune encephalomyelitis (EAE), 80% used mice, and 76% used fe-male animals. Neither outcomes of animal studies nor testing a DMT under more diverse experimental settings, e.g., across different laboratories or animal models, were associated with successful approval. Surprisingly, 91% of animal studies were published after first-in-MS trial and 91% after official regu-latory approval.Our study underscores specific challenges in translating animal research to clinical practice, including limited experimental methods, and a potential disconnect between preclinical and clinical research. We advocate for increasing experimental variability and efforts to streamline drug development for MS to improve animal research’s relevance to patient care.\n\n\n\n\n\n\n\n\n\nFriederike Kohrs - Communities for Open Research Synthesis – accelerating the translation of evidence by integrating preclinical systematic reviews into the research pipeline\n\n\n\n\n\nCharité | BIH QUEST Center for Responsible Research\nKohrs, Friederike Elisabeth; Vojvodic, Sofija; Karmakar, Mala; Rackoll, Torsten; Bannach-Brown, Alexandra; McCann, Sarah\nOur project Communities for Open Research Synthesis (COReS) develops a targeted framework to initiate systemic change in how preclinical evidence from laboratory studies is translated into improved human health outcomes. Systematic review and meta-analysis act as an evidence-based bridge when translating scientific findings. These techniques allow us to identify what we currently know, how reliable evidence is, and where future research is needed, thereby increasing the possibility for successful translation. COReS aims for long-lasting change in how research is designed, conducted, and disseminated considering up-to-date evidence. We leverage existing community expertise and develop sustainable implementation, thereby advancing high-quality research. We employ a three-pillar approach to integrate preclinical systematic reviews into the research pipeline. Education: Comprehensive education grows awareness of the benefits of preclinical systematic review and builds capacity and methodological competence. In addition to live workshops, we have developed freely available eLearning modules. Our “train-the-trainer” programme enables qualified researchers to educate others at their institutions, effectively delivering education at scale. Infrastructure: To carry out preclinical systematic reviews, appropriate infrastructure and support is required. We build on existing software, Systematic Review Facility (SyRF), expanding to support helpdesk enquiries, and optimise user experience and documentation. We collaboratively develop new features and integrate novel automation tools into SyRF, reducing resources associated with conducting systematic reviews. Community: Forging communities to address the disconnect between primary research and evidence synthesis is instrumental. Our digital hub combines resources, tools, and support and our online open community forum facilitates sharing of standards and discussion of methodological questions, allowing for new collaborations to be formed. Partner institutions across Germany are currently piloting this blueprint for initiating communities, ensuring adaptability to different institutions and biomedical research fields. COReS creates interdisciplinary networks to address challenges of preclinical and translational research, facilitating decision-making in research prioritisation. “Please note: our results and outlook section has been submitted in the results section of the abstract submission form”\n\n\n\n\n\n\n\n\n\nMayerli Andrea Prado Rivera - Effects of early-life stress on social functioning in depression: A systematic review and meta-analysis of mouse and rat studies\n\n\n\n\n\n\nBehavioural Neuroscience, Groningen Institute for Evolutionary Life Sciences, University of Groningen,The Netherlands; (2) Department of Anaesthesiology, Pain and Palliative Care, Radboud University Medical Centre, The Netherlands\n\nPrado-Rivera, Mayerli Andrea(1); Deddens, Verena(1); Fortuin, Annemarijn(1); Wever, Kimberley E.(2); Olivier, Jocelien D.A.(1)\nAbout 5% of adult population experience depression. People that experienced early-life stress are more likely to develop depression. Increasing evidence shows that maternal stress before conception (pregestational stress) and during pregnancy (prenatal stress) also increase the risk for depression in the offspring. Depression is linked to social impairments, however, underlying mechanisms of social deficits associated with depression are poorly understood, limiting targeted treatment of these symptoms in the clinical setting. By systematically reviewing rodent studies on depression induced by early-life and maternal (prenatal and pregestational) stress, depression-related social deficits can be characterized and underlying mechanisms revealed. This critical assessment of literature will help to elucidate how early-life and maternal stress contribute to social impairments in depression and provide insights for future human studies where social deficits in depression are found to reveal important targets for therapeutics in depressed patients.To systematically analyze the effects of pregestational, prenatal and postnatal early-life stress (ELS) exposure on depression-related social behaviors in mouse and rat models.The methodology of our review has been prospectively registered in PROSPERO (#CRD42024552870). We performed a comprehensive literature search in PubMed and EMBASE, employing controlled vocabularies unique to each database for maximum sensitivity. To select relevant studies for data collection, title/abstract and full-text screening were conducted. Eligibility criteria followed the PICO structure that was used to formulate the review question. Screening of reference lists of included studies is currently ongoing to complement the comprehensive search results. Next steps include: 1) extraction of study characteristics (eg., time window of ELS manipulation, type of stressor); 2) extraction of primary outcomes of social behaviors that can be categorized into one of the following social behavioral constructs: social affiliation/attachment, social communication, or social cognition; 3) quality assessment of selected studies by using SYRCLE’s risk of bias tool for animal studies.NANA\n\n\n\n\n\n\n\n\n\nTorsten Rackoll - An interactive shiny application to support critical appraisal training in preclinical evidence synthesis\n\n\n\n\n\nBIH QUEST Center for Responsible Research, Berlin Institute of Health at Universitätsmedizin Berlin (Rackoll, Economou, McCann); Department of Anesthesiology, Radboud Institute for Health Sciences, Radboud University Medical Center, Nijmegen, The Netherlands (Weaver)\nRackoll, Torsten; Economou, Maria; Weaver, Kim; McCann, Sarah\nThe quality of synthesized evidence is a key factor that influences the validity of conclusions drawn from a systematic review. In the preclinical field, specific tools have been developed to assess methodological and reporting quality of primary evidence, and their widespread adoption in evidence synthesis is still growing. At the same time, teaching critical appraisal can be very resource-intensive, as it often requires domain-specific exposure and extensive training. To present an interactive shiny application to support critical appraisal training in preclinical evidence synthesis Motivated by the need to optimize critical appraisal training in the preclinical field, we report the development of an interactive shiny web application, based on the SYRCLE risk of bias (RoB) tool for preclinical studies (Hooijmans et al., 2014). The application is based on a self-developed flow chart incorporating guiding questions to facilitate decision making. This application aims to serve as a self-paced learning resource that allows users to work through all the steps of performing a RoB assessment of animal experiments in a user-friendly environment. The browser-based app also provides detailed information and real-life examples on the different types of biases that could affect preclinical studies, while integrating recently developed tools such as robvis (McGuinness and Higgins, 2020) to visualize the results. This application could be used as a stand-alone resource, as well as a tool to be incorporated in curricula/workshops teaching critical appraisal and (preclinical) systematic reviews. Our aim is to present the application and provide an overview of the implemented features. In addition, we thrive to facilitate an open discussion around an upgrade of the current RoB tool to incorporate experiences made since 2014.\n\n\n\n\n\n\n\n\n\nFiona Ramage - Systematic evaluation of the overlap of disease model induction procedures used and behavioural outcomes assessed in animal models of anxiety, depression, and psychosis\n\n\n\n\n\n1 Centre for Clinical Brain Sciences, University of Edinburgh, Edinburgh EH8 9YL, UK 2 Berlin Institute of Health at Charité, Universitätsmedizin Berlin, Charitéplatz 1, 10117, Berlin, Germany\nFiona Ramage1, Kaitlyn Hair1, Sean Smith1, Emma Wilson1, Alexandra Bannach-Brown2, Francesca Tinsdeall1, Charis Wong1, Emily Sena1, Malcolm Macleod1\nIn vivo psychiatry research is heterogenous with diverse disease models and behavioural assays to evaluate psychiatric symptoms The field faces challenges with synthesising a large and rapid-growing body of evidence. Historically, the psychiatric condition claiming to be modelled in an animal is defined based on context and the study authors’ intentions, but we suspect substantial overlap between procedures used to model anxiety, depression, and psychosis and behavioural assays used to evaluate these. As such, current systematic or other literature search approaches to identify preclinical studies relevant to a specific disease area (i.e. using disease-specific search terms) may be limited, and better approaches could be developed to enrich them.We aim to quantify the overlap of disease model induction procedures, therapeutic interventions, and behavioural outcomes in preclinical research claiming to model depression, anxiety, or psychosis, by observing their presence in 3 distinct disease-specific databases. We develop Systematic Online Living Evidence Summary (SOLES), curated databases using semi-automated methodologies specifically for preclinical anxiety, depression, and psychosis research to tackle these issues. We will retrieve summaries of all disease models, interventions, and behavioural outcomes featuring in each database tagged using text-mining regex-based tools, and specifically capture those featuring in more than one SOLES database. We will adopt a similar approach for model-outcome pairs and outcome-outcome pairs (where multiple outcomes are measured within a single study). We anticipate finding substantial overlap between SOLES databases for anxiety, depression, and psychosis in models, interventions, and outcomes featuring, and relationships between these. Similarities in models, interventions, and outcomes present in these historically distinct disease areas would support research efforts to integrate evidence across these disease-based siloes. Creating a database like a unified SOLES combining all three entities would enable better capture of relevant evidence for researchers in in vivo psychiatric research.\n\n\n\n\n\n\n\n\n\nChris Sena - SyRF: The Systematic Review Facility - A web-based application for managing and performing preclinical systematic reviews\n\n\n\n\n\nCAMARADES, The University of Edinburgh\nKarmakar, Mala; Bannach-Brown, Alexandra; Macleod, Malcolm; Sena, Emily; Currie, Gillian; Sena, Chris\nSystematic Review Facility (SyRF) is an online platform for conducting systematic reviews of preclinical studies. Launched in 2016, SyRF supports various systematic reviews addressing different experimental designs and research questions. It allows users to adopt emerging automated tools, supports best practices, and enables collaborative teams to screen studies independently, regardless of location.We present the key features, infrastructure, and benefits of SyRF for improving the efficiency and accuracy of systematic reviews, particularly for researchers dealing with large datasets. Our ethos is rooted in open science and transparency, with all interactions recorded and reportable. We also showcase the latest features available to users. SyRF is an open-access web application featuring a frontend user interface built with Angular, an ASP.Net Core Web API, and secure data storage in MongoDB. Its infrastructure is designed for horizontal scalability, allowing it to handle increasing demands efficiently. The user interface ensures a seamless user experience, while the robust backend and secure data storage provide reliable performance and data integrity. A typical workflow in SyRF includes: Creating a project; Configuring stages; Defining annotation questions; Uploading studies in systematic searches; Inviting users to join the project; Reviewing studies (screening, annotating, extracting quantitative data); Exporting data for analysis; Since SyRF’s launch, we have maintained a growing user base and implemented new features requested by users. The integration of a user-friendly interface with powerful backend processing capabilities allows researchers to focus on critical analysis rather than manual data handling. We present the latest features released to SyRF, updated figures for the number of users, projects supported, and the locations of scientists using SyRF.Future developments will utilise AI-driven functionality to support rapid data extraction and analysis. SyRF remains a freely available resource for the systematic review community, and we invite feedback and requests for new features.\n\n\n\n\n\n\n\n\n\nSean Smith - Systematic Online Living Evidence Summaries (SOLES): Meeting Demand for Rapid, Rigorous, and Redefined Evidence Synthesis\n\n\n\n\n\nUniversity of Edinburgh\nSmith, S. (1); Economou, E. (2), Wilson, E. (1), Bannach-Brown, A. (2), Wong, C. (2), Hair, K. (1)\nPreclinical systematic reviews are labour-intensive to conduct and often struggle to keep pace with the emergence of new evidence. For research areas with a high publication rate, there is often a lack of efficient synthesis to guide future research and inform translation. Using automated tools and machine learning techniques, we have established Systematic Online Living Evidence Summaries (SOLES) platforms across several research fields. SOLES acts as a tool for resource users to identify and interrogate existing data, facilitating further synthesis and re-use.To meet the growing demand for SOLES platforms, we aimed to develop scalable approaches. Our objectives were to fully automate the SOLES workflow, optimize the production of our web applications and create an open-source R package to facilitate the use and further development of SOLES by others.We developed a fully automated workflow, which includes database searches, removal of duplicate records, article screening for inclusion, study characteristic tagging, and web-app redeployment. We unified the relational database structure across SOLES to simplify maintenance and allow for data integration. To streamline web application development, we used modularization to create reproducible “building blocks” for individual application elements. More recently, we have been developing a system which leverages AI to extract study characteristics which our previous natural language processing method struggled to identify. Our scalable infrastructure supports over 10 SOLES projects at various development stages. Aligning our approaches has enabled the integration of multiple evidence domains, allowing for disease-agnostic interrogation and new discoveries.SOLES platforms represent a significant advancement, enabling rapid, rigorous, and redefined approaches to evidence synthesis. Our efforts ensure that researchers and other stakeholders can access and use the latest evidence efficiently, paving the way for accelerated synthesis.\n\n\n\n\n\n\n\n\n\nJulia Steitz - Development of a Systematic Online Living Evidence Summary (SOLES) for Animal Models testing Targeted Therapies against Cancer\n\n\n\n\n\nCAMARADES Berlin, QUEST Center for Responsible Research, Berlin Institute of Health at Charité (BIH), Berlin, Germany; Institute for Laboratory Animal Science, Faculty of Medicine, RWTH Aachen University, Aachen, Germany\nMcCann, Sarah; Bannach-Brown, Alexandra; Mirzaei, Yalda; Ahmadvand, Ardalan; Economou, Maria; Steitz, Julia\nCancer is a leading cause of death worldwide and new therapies are needed, necessitating testing in animal models. Although a wide variety of tumor models have been described in the literature, their limitations, as well as unsuccessful translation attempts are often not reported. Yet, choosing the right animal model for the drug to be tested and successfully translated into the clinic is critical. We will systematically review studies testing targeted therapies using preclinical tumor models. Our aim is to shed light on the animal models which have been successfully tested in cancer research and identify variables that contribute to successful translation and markers of high external validity such as FDA approval. Given the substantial number of studies potentially relevant to this topic, we are developing and validating an automated approach to categorize and prioritize studies before focusing on in-depth review of disease domains with potential for greatest impact. We will establish and validate the approach in disease domains with a manageable number of publications, to demonstrate the feasibility of extension to other tumor entities.: The results will be implemented in an interrogatable database accessed through a user-friendly online dashboard that can be used to filter studies based on study design features of interest (Systematic Online Living Evidence Summary; SOLES). The dashboard will be used to support the conduct of specific systematic reviews and highlight gaps in the literature for future research. The Cancer-SOLES platform will provide novel opportunities to identify drug and model combinations that show concordance with human outcomes but will also identify which models did not show a successful translation. With this tool, we aim to facilitate and accelerate the model selection process for preclinical cancer studies and to reduce the number of animals used in cancer research.\n\n\n\n\n\n\n\n\n\nSofija Vojvodic - Addressing External Validity in Animal Stroke Research: Systematic Review and Meta-Analysis of Sex Differences in Ischemic Models\n\n\n\n\n\nBerlin Institute of Health at Charite; Berlin Institute of Health at Charite; Berlin Institute of Health at Charite; Center for Stroke Research Charite University of Medicine; Berlin Institute of Health at Charite\nRackoll, Torsten; Shum Yee Khor, Yvonne; Celebi, Ceren; Harms, Christoph; McCann, Sarah\nIschemic stroke is a leading cause of global disability, yet its precise pathogenic mechanisms remain elusive, limiting the effectiveness of current treatments. This problem is compounded by animal models that often fail to accurately represent key patient characteristics such as health status and age. Furthermore, these models predominantly use male subjects, despite stroke affecting all genders. This male-centric focus in research means that treatments validated in these models may be ineffective or even harmful for females. Understanding sex differences in stroke is crucial for translating findings from animal models to human patients. This systematic review aims to provide a more nuanced understanding of how sex influences stroke outcomes and treatment efficacy. By examining both male and female subjects, we can uncover differences in pathophysiological pathways and treatment responses that are critical for developing effective, personalized interventions for both sexes. Our methods followed a pre-registered protocol (PROSPERO ID CRD42023495731) to investigate sex differences in stroke severity, treatment effects, and mechanisms of injury, protection, and repair. We searched for in vivo stroke studies using animals of both sexes in Embase via OVID, the Web of Science preprint collection, and Stroke-SOLES, a custom-made tool that uses machine learning to filter for animal stroke experiments. This approach yielded 4896 unique records. After title and abstract screening by at least two independent reviewers, 1396 studies were included. Full-text screening, data extraction, and risk of bias assessment have been done by two independent reviewers, with discrepancies reconciled by a third. Preliminary findings were obtained on single reviewer extractions. Normalised mean difference effect sizes were calculated, and random effects meta-analysis was applied to combine effects.Preliminary analysis showed that female animals have on average 32.5% smaller infarct volumes than males. Univariate meta-regression showed that this difference was present in young but not in aged or middle-aged animals. However, the amount of remaining heterogeneity was high. No sex differences were found in post-stroke survival rates. Most studies had unclear or high risk of bias assessments across all domains, except for selection bias where 70% of studies were at low risk of being biased by unequal baseline characteristics between sexes.Male animals exhibit larger infarct volumes compared to females, yet this does not result in higher mortality. Notably, in line with clinical observations, sex differences in stroke are influenced by age, implying a role of sex hormones in stroke pathophysiology. While various mechanisms underlying these sex differences have been suggested, further investigation is necessary to fully understand them. Furthermore, the majority of included studies are of poor quality, impeding the ability to draw reliable conclusions. As our systematic review progresses, we will supplement these preliminary findings with further investigations of factors contributing to heterogeneity, sex differences in treatment efficacy and mechanisms of stroke injury, protection and repair."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "SR-SAVI Conference",
    "section": "",
    "text": "Your browser does not support the video tag."
  },
  {
    "objectID": "about.html#organizers",
    "href": "about.html#organizers",
    "title": "SR-SAVI Conference",
    "section": "Organizers",
    "text": "Organizers\nLet’s give credit where credit is due. This conference would be be possible without our amazing team:\n\nMarianna Rosso\nBenjamin Ineichen\nSarah McCann\nKimberley Wever\nAndrew Rooney\nEmily Sena"
  },
  {
    "objectID": "about.html#feeback",
    "href": "about.html#feeback",
    "title": "SR-SAVI Conference",
    "section": "Feeback",
    "text": "Feeback\n\nLoading…"
  },
  {
    "objectID": "about.html#credits",
    "href": "about.html#credits",
    "title": "SR-SAVI Conference",
    "section": "Credits",
    "text": "Credits\nThis website was created with Quarto by Marianna Rosso. After the event this website will be migrated here."
  },
  {
    "objectID": "SocialEvent.html",
    "href": "SocialEvent.html",
    "title": "SR-SAVI Conference",
    "section": "",
    "text": "Your browser does not support the video tag.\nJoin us for a memorable social event featuring a Happy Hour (starting at 19:00) followed by a 5-course dinner at the Uto Kulm Restaurant, located on the scenic Uetliberg in Zürich, on us!\nYou can reach the top either by a quick train ride or enjoy a leisurely 45-minute hike, taking in the beautiful views of the city and surrounding nature. It’s the perfect way to relax and network after a day of engaging discussions!"
  },
  {
    "objectID": "SocialEvent.html#by-foot",
    "href": "SocialEvent.html#by-foot",
    "title": "SR-SAVI Conference",
    "section": "By foot:",
    "text": "By foot:\nMeet Benjamin at the Central bus and tram station, at Zähringerstrasse 51 (point A in the map below) at 17:00. You will walk to Zürich HB (point B) from there at take the train S10 at 17:25 to Zürich Triemli (point C) where the hike will start. The hike will take you near the Uetliberg train station (point D) in around 45-60 minutes. From there, a short 10 minute walk will take you to the Utokulm restaurant (point E)."
  },
  {
    "objectID": "SocialEvent.html#by-train",
    "href": "SocialEvent.html#by-train",
    "title": "SR-SAVI Conference",
    "section": "By train:",
    "text": "By train:\nMeet Marianna at the Central bus and tram station, at Zähringerstrasse 51 (point A in the map below) at 18:00. You will walk to Zürich HB (point B) from there at take the train S10 at 18:35 to Zürich Uetliberg (point D). Train tickets will be available for purchase at the train station. From there, a short 10 minute walk will take you to the Utokulm restaurant (point E)."
  },
  {
    "objectID": "RepoChallenge.html",
    "href": "RepoChallenge.html",
    "title": "SR-SAVI Conference",
    "section": "",
    "text": "Your browser does not support the video tag. \n\nInformation to follow soon!"
  }
]